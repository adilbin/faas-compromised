{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b168fcb7",
      "metadata": {},
      "source": [
        "## Feature: Syscall only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b2c30a72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 6\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1831628e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n",
            "\n",
            "Vocabulary size: 81 (including PAD)\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs(file_path):\n",
        "    \"\"\"Load syscalls grouped by run.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = df.groupby('run')['syscall'].apply(list).tolist()\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n",
        "\n",
        "# Collect all syscalls for building vocabulary\n",
        "all_syscalls = []\n",
        "for path, _ in train_files + test_files:\n",
        "    for run in load_runs(path):\n",
        "        all_syscalls.extend(run)\n",
        "\n",
        "# Build syscall encoder (add PAD token at index 0)\n",
        "syscall_encoder = LabelEncoder()\n",
        "syscall_encoder.fit(all_syscalls)\n",
        "vocab_size = len(syscall_encoder.classes_) + 1  # +1 for PAD token\n",
        "PAD_IDX = 0\n",
        "print(f\"\\nVocabulary size: {vocab_size} (including PAD)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0ba47887",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SyscallDataset(Dataset):\n",
        "    def __init__(self, file_label_pairs, encoder, max_len):\n",
        "        self.sequences = []\n",
        "        self.labels = []\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs(path)\n",
        "            for run_syscalls in runs:\n",
        "                # Encode syscalls (+1 to reserve 0 for PAD)\n",
        "                encoded = encoder.transform(run_syscalls) + 1\n",
        "                \n",
        "                # Truncate or pad to max_len\n",
        "                if len(encoded) > max_len:\n",
        "                    encoded = encoded[:max_len]\n",
        "                else:\n",
        "                    encoded = np.pad(encoded, (0, max_len - len(encoded)), constant_values=PAD_IDX)\n",
        "                \n",
        "                self.sequences.append(encoded)\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.sequences = np.array(self.sequences)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.sequences[idx], dtype=torch.long),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d7341005",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, max_len, embed_dim=64, num_heads=4, num_layers=2, ff_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
        "        self.pos_encoding = nn.Parameter(torch.zeros(1, max_len, embed_dim))\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "        \n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.pos_encoding, std=0.02)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Create padding mask (True for PAD positions)\n",
        "        padding_mask = (x == PAD_IDX)\n",
        "        \n",
        "        # Embedding + positional encoding\n",
        "        x = self.embedding(x) + self.pos_encoding[:, :x.size(1), :]\n",
        "        \n",
        "        # Transformer encoder\n",
        "        x = self.transformer(x, src_key_padding_mask=padding_mask)\n",
        "        \n",
        "        # Global average pooling (excluding padding)\n",
        "        mask_expanded = (~padding_mask).unsqueeze(-1).float()\n",
        "        x = (x * mask_expanded).sum(dim=1) / (mask_expanded.sum(dim=1) + 1e-9)\n",
        "        \n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4a33516f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 92,418\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.2768, Acc: 0.8766\n",
            "Epoch 5/6 - Loss: 0.0227, Acc: 0.9940\n",
            "Training time: 189.58s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 2.55s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.82      0.90       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.90      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              400               89\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1820\n",
            "F1-score (weighted): 0.8877\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 108,418\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.2772, Acc: 0.8877\n",
            "Epoch 5/6 - Loss: 0.0150, Acc: 0.9965\n",
            "Training time: 627.14s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 4.90s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.82      0.90       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.90      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              399               90\n",
            "True: malicious             2              319\n",
            "\n",
            "Detection Rate: 0.9938\n",
            "False Positive Rate: 0.1840\n",
            "F1-score (weighted): 0.8877\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 140,418\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.2897, Acc: 0.8822\n",
            "Epoch 5/6 - Loss: 0.0056, Acc: 0.9990\n",
            "Training time: 2265.30s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 8.43s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.81      0.90       489\n",
            "   malicious       0.78      1.00      0.87       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              397               92\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.1881\n",
            "F1-score (weighted): 0.8876\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 204,418\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.3181, Acc: 0.8751\n",
            "Epoch 5/6 - Loss: 0.0077, Acc: 0.9985\n",
            "Training time: 8463.57s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 14.74s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.82      0.90       489\n",
            "   malicious       0.78      1.00      0.88       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              399               90\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.1840\n",
            "F1-score (weighted): 0.8901\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = SyscallDataset(train_files, syscall_encoder, window_size)\n",
        "    test_dataset = SyscallDataset(test_files, syscall_encoder, window_size)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = TransformerEncoder(vocab_size, max_len=window_size).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cb1e86d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.9907              0.1820              0.8877         189.58          2.55\n",
            "         500         0.9938              0.1840              0.8877         627.14          4.90\n",
            "        1000         1.0000              0.1881              0.8876        2265.30          8.43\n",
            "        2000         1.0000              0.1840              0.8901        8463.57         14.74\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3367a622",
      "metadata": {},
      "source": [
        "## Feature: Return values only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9750be71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 6\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2a8d60c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n",
            "\n",
            "Vocabulary size: 42586 (including PAD)\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_retval(file_path):\n",
        "    \"\"\"Load return values grouped by run.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = df.groupby('run')['Ret'].apply(list).tolist()\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_retval(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n",
        "\n",
        "# Collect all return values for building vocabulary\n",
        "all_retvals = []\n",
        "for path, _ in train_files + test_files:\n",
        "    for run in load_runs_retval(path):\n",
        "        all_retvals.extend(run)\n",
        "\n",
        "# Build return value encoder (add PAD token at index 0)\n",
        "retval_encoder = LabelEncoder()\n",
        "retval_encoder.fit(all_retvals)\n",
        "vocab_size = len(retval_encoder.classes_) + 1  # +1 for PAD token\n",
        "PAD_IDX = 0\n",
        "print(f\"\\nVocabulary size: {vocab_size} (including PAD)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3b8b9668",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RetvalDataset(Dataset):\n",
        "    def __init__(self, file_label_pairs, encoder, max_len):\n",
        "        self.sequences = []\n",
        "        self.labels = []\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs_retval(path)\n",
        "            for run_retvals in runs:\n",
        "                # Encode return values (+1 to reserve 0 for PAD)\n",
        "                encoded = encoder.transform(run_retvals) + 1\n",
        "                \n",
        "                # Truncate or pad to max_len\n",
        "                if len(encoded) > max_len:\n",
        "                    encoded = encoded[:max_len]\n",
        "                else:\n",
        "                    encoded = np.pad(encoded, (0, max_len - len(encoded)), constant_values=PAD_IDX)\n",
        "                \n",
        "                self.sequences.append(encoded)\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.sequences = np.array(self.sequences)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.sequences[idx], dtype=torch.long),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5527e165",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, max_len, embed_dim=64, num_heads=4, num_layers=2, ff_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
        "        self.pos_encoding = nn.Parameter(torch.zeros(1, max_len, embed_dim))\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "        \n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.pos_encoding, std=0.02)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Create padding mask (True for PAD positions)\n",
        "        padding_mask = (x == PAD_IDX)\n",
        "        \n",
        "        # Embedding + positional encoding\n",
        "        x = self.embedding(x) + self.pos_encoding[:, :x.size(1), :]\n",
        "        \n",
        "        # Transformer encoder\n",
        "        x = self.transformer(x, src_key_padding_mask=padding_mask)\n",
        "        \n",
        "        # Global average pooling (excluding padding)\n",
        "        mask_expanded = (~padding_mask).unsqueeze(-1).float()\n",
        "        x = (x * mask_expanded).sum(dim=1) / (mask_expanded.sum(dim=1) + 1e-9)\n",
        "        \n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cbf363ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 2,812,738\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.3241, Acc: 0.8620\n",
            "Epoch 5/6 - Loss: 0.0238, Acc: 0.9955\n",
            "Training time: 197.73s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 2.54s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.83      0.90       489\n",
            "   malicious       0.79      0.99      0.88       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              404               85\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1738\n",
            "F1-score (weighted): 0.8925\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 2,828,738\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.3219, Acc: 0.8620\n",
            "Epoch 5/6 - Loss: 0.0067, Acc: 0.9985\n",
            "Training time: 67.34s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.40s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.99      0.99       489\n",
            "   malicious       0.99      1.00      0.99       321\n",
            "\n",
            "    accuracy                           0.99       810\n",
            "   macro avg       0.99      0.99      0.99       810\n",
            "weighted avg       0.99      0.99      0.99       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              485                4\n",
            "True: malicious             1              320\n",
            "\n",
            "Detection Rate: 0.9969\n",
            "False Positive Rate: 0.0082\n",
            "F1-score (weighted): 0.9938\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 2,860,738\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.4133, Acc: 0.8157\n",
            "Epoch 5/6 - Loss: 0.0148, Acc: 0.9975\n",
            "Training time: 2278.55s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 8.49s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.82      0.90       489\n",
            "   malicious       0.78      1.00      0.88       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              399               90\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.1840\n",
            "F1-score (weighted): 0.8901\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Model parameters: 2,924,738\n",
            "\n",
            "Training...\n",
            "Epoch 1/6 - Loss: 0.3524, Acc: 0.8444\n",
            "Epoch 5/6 - Loss: 0.0039, Acc: 0.9995\n",
            "Training time: 8481.32s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 14.81s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.82      0.90       489\n",
            "   malicious       0.78      1.00      0.88       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              399               90\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.1840\n",
            "F1-score (weighted): 0.8901\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = RetvalDataset(train_files, retval_encoder, window_size)\n",
        "    test_dataset = RetvalDataset(test_files, retval_encoder, window_size)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = TransformerEncoder(vocab_size, max_len=window_size).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "80b57e73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.9907              0.1738              0.8925         197.73          2.54\n",
            "         500         0.9969              0.0082              0.9938          67.34          0.40\n",
            "        1000         1.0000              0.1840              0.8901        2278.55          8.49\n",
            "        2000         1.0000              0.1840              0.8901        8481.32         14.81\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "618c8f19",
      "metadata": {},
      "source": [
        "## Feature: Parameters only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3c052424",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Loading sentence transformer model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fab3092189d4f0eaf8a4cdd2c6785a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c1db7e7da8b4354add2390f91a71bae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b30e565da094183a396be4f2d75a3aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b82c2411d10d4789bf11a9894e197036",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ac426359fd14fdb96eaf2938ab8614c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "354115d3aa9f472884e32db205bfdce6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95e5ffadf6434434bbaabe7c18c37951",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cddcdccac0dd41d6a2b42c07a39175d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71eeec35b7c64e2e923dbc635526c400",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df8fe3a8403843ca987adb2e6983b204",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "980cb6afee2d4242baf222c74454b0c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 6\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Load sentence transformer model for semantic embeddings\n",
        "# Using a lightweight model that produces 384-dim embeddings\n",
        "# Keep on CPU to save GPU memory for training\n",
        "print(\"Loading sentence transformer model...\")\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
        "EMBEDDING_DIM = sentence_model.get_sentence_embedding_dimension()\n",
        "print(f\"Sentence embedding dimension: {EMBEDDING_DIM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8320ed3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_params_raw(file_path):\n",
        "    \"\"\"Load raw parameter strings grouped by run (list of param strings per run).\n",
        "    \n",
        "    Returns list of runs, where each run is a list of parameter strings (one per syscall).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = []\n",
        "    for run_id, group in df.groupby('run'):\n",
        "        # Keep parameters as list of strings (one per syscall)\n",
        "        run_params = group['parameters'].tolist()\n",
        "        runs.append(run_params)\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_params_raw(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ed2d7c5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unique parameter strings...\n",
            "Unique parameter strings: 266019\n",
            "Computing sentence embeddings (this may take a few minutes)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9895b88e01e0478092760e50bf00da7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1040 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings computed. Shape per embedding: 384\n"
          ]
        }
      ],
      "source": [
        "# Pre-compute sentence embeddings for all unique parameter strings\n",
        "# This avoids re-encoding the same strings multiple times and saves memory\n",
        "print(\"Collecting unique parameter strings...\")\n",
        "\n",
        "unique_params = set()\n",
        "for path, _ in train_files + test_files:\n",
        "    for run_params in load_runs_params_raw(path):\n",
        "        for param_str in run_params:\n",
        "            # Convert to string and handle NaN\n",
        "            if pd.isna(param_str):\n",
        "                unique_params.add('<EMPTY>')\n",
        "            else:\n",
        "                unique_params.add(str(param_str))\n",
        "\n",
        "unique_params = list(unique_params)\n",
        "print(f\"Unique parameter strings: {len(unique_params)}\")\n",
        "\n",
        "# Compute embeddings for all unique strings in batches\n",
        "print(\"Computing sentence embeddings (this may take a few minutes)...\")\n",
        "param_embeddings = sentence_model.encode(\n",
        "    unique_params, \n",
        "    show_progress_bar=True, \n",
        "    batch_size=256,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "# Create a mapping from parameter string to embedding\n",
        "param_to_embedding = {param: emb for param, emb in zip(unique_params, param_embeddings)}\n",
        "print(f\"Embeddings computed. Shape per embedding: {EMBEDDING_DIM}\")\n",
        "\n",
        "# Create a zero embedding for padding\n",
        "PAD_EMBEDDING = np.zeros(EMBEDDING_DIM, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bfd34685",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ParamsEmbeddingDataset(Dataset):\n",
        "    \"\"\"Dataset that uses pre-computed sentence embeddings for parameter strings.\n",
        "    \n",
        "    Instead of tokenizing each parameter string into multiple tokens,\n",
        "    we embed each parameter string as a single vector using a sentence transformer.\n",
        "    This reduces sequence length from window_size * tokens_per_syscall to just window_size.\n",
        "    \"\"\"\n",
        "    def __init__(self, file_label_pairs, param_to_embedding, window_size, embed_dim, pad_embedding):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            file_label_pairs: List of (file_path, label) tuples\n",
        "            param_to_embedding: Dict mapping parameter strings to embeddings\n",
        "            window_size: Number of syscalls (parameter strings) to consider from each run\n",
        "            embed_dim: Dimension of sentence embeddings\n",
        "            pad_embedding: Zero embedding for padding\n",
        "        \"\"\"\n",
        "        self.embeddings = []\n",
        "        self.labels = []\n",
        "        self.window_size = window_size\n",
        "        self.embed_dim = embed_dim\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs_params_raw(path)\n",
        "            for run_params in runs:\n",
        "                # Take first window_size parameter strings from this run\n",
        "                params_to_use = run_params[:window_size]\n",
        "                \n",
        "                # Get embedding for each parameter string\n",
        "                run_embeddings = []\n",
        "                for param_str in params_to_use:\n",
        "                    if pd.isna(param_str):\n",
        "                        key = '<EMPTY>'\n",
        "                    else:\n",
        "                        key = str(param_str)\n",
        "                    run_embeddings.append(param_to_embedding[key])\n",
        "                \n",
        "                # Pad to window_size if needed\n",
        "                while len(run_embeddings) < window_size:\n",
        "                    run_embeddings.append(pad_embedding)\n",
        "                \n",
        "                self.embeddings.append(np.array(run_embeddings, dtype=np.float32))\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.embeddings = np.array(self.embeddings)  # Shape: (num_samples, window_size, embed_dim)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.embeddings[idx], dtype=torch.float32),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8bdec4d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerEncoderForEmbeddings(nn.Module):\n",
        "    \"\"\"Transformer encoder that takes pre-computed embeddings as input.\n",
        "    \n",
        "    Unlike the standard version that has an embedding layer,\n",
        "    this version expects inputs to already be embedded (float tensors).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, max_len, hidden_dim=128, num_heads=4, num_layers=2, ff_dim=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Project input embeddings to hidden dimension\n",
        "        self.input_projection = nn.Linear(input_dim, hidden_dim)\n",
        "        self.pos_encoding = nn.Parameter(torch.zeros(1, max_len, hidden_dim))\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "        \n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.pos_encoding, std=0.02)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, input_dim)\n",
        "        # Detect padding by checking if embedding is all zeros\n",
        "        padding_mask = (x.abs().sum(dim=-1) == 0)  # True for padded positions\n",
        "        \n",
        "        # Project to hidden dimension and add positional encoding\n",
        "        x = self.input_projection(x) + self.pos_encoding[:, :x.size(1), :]\n",
        "        \n",
        "        # Transformer encoder\n",
        "        x = self.transformer(x, src_key_padding_mask=padding_mask)\n",
        "        \n",
        "        # Global average pooling (excluding padding)\n",
        "        mask_expanded = (~padding_mask).unsqueeze(-1).float()\n",
        "        x = (x * mask_expanded).sum(dim=1) / (mask_expanded.sum(dim=1) + 1e-9)\n",
        "        \n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f4839fd9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250 syscalls\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Sequence length: 250 (1 embedding per syscall parameter)\n",
            "Input embedding dim: 384\n",
            "Model parameters: 354,626\n",
            "\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/6: 100%|| 63/63 [00:05<00:00, 12.33it/s, loss=0.0169, acc=0.7533]\n",
            "Epoch 2/6: 100%|| 63/63 [00:04<00:00, 12.64it/s, loss=0.0224, acc=0.6883]\n",
            "Epoch 3/6: 100%|| 63/63 [00:05<00:00, 12.59it/s, loss=0.0124, acc=0.8293]\n",
            "Epoch 4/6: 100%|| 63/63 [00:05<00:00, 12.59it/s, loss=0.0023, acc=0.9854]\n",
            "Epoch 5/6: 100%|| 63/63 [00:04<00:00, 12.60it/s, loss=0.0010, acc=0.9950]\n",
            "Epoch 6/6: 100%|| 63/63 [00:04<00:00, 12.60it/s, loss=0.0009, acc=0.9950]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 30.12s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.55s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.82      0.90       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              401               88\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1800\n",
            "F1-score (weighted): 0.8889\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500 syscalls\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Sequence length: 500 (1 embedding per syscall parameter)\n",
            "Input embedding dim: 384\n",
            "Model parameters: 386,626\n",
            "\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/6: 100%|| 63/63 [00:14<00:00,  4.23it/s, loss=0.0105, acc=0.8560]\n",
            "Epoch 2/6: 100%|| 63/63 [00:15<00:00,  3.98it/s, loss=0.0027, acc=0.9839]\n",
            "Epoch 3/6: 100%|| 63/63 [00:17<00:00,  3.70it/s, loss=0.0004, acc=0.9975]\n",
            "Epoch 4/6: 100%|| 63/63 [00:16<00:00,  3.73it/s, loss=0.0004, acc=0.9980]\n",
            "Epoch 5/6: 100%|| 63/63 [02:15<00:00,  2.15s/it, loss=0.0004, acc=0.9980]\n",
            "Epoch 6/6: 100%|| 63/63 [02:19<00:00,  2.22s/it, loss=0.0010, acc=0.9935]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 339.68s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 8.26s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.90      0.94       489\n",
            "   malicious       0.86      1.00      0.92       321\n",
            "\n",
            "    accuracy                           0.94       810\n",
            "   macro avg       0.93      0.95      0.93       810\n",
            "weighted avg       0.94      0.94      0.94       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              438               51\n",
            "True: malicious             1              320\n",
            "\n",
            "Detection Rate: 0.9969\n",
            "False Positive Rate: 0.1043\n",
            "F1-score (weighted): 0.9364\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000 syscalls\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Sequence length: 1000 (1 embedding per syscall parameter)\n",
            "Input embedding dim: 384\n",
            "Model parameters: 450,626\n",
            "\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/6: 100%|| 63/63 [07:44<00:00,  7.37s/it, loss=0.0138, acc=0.8132]\n",
            "Epoch 2/6: 100%|| 63/63 [07:44<00:00,  7.37s/it, loss=0.0008, acc=0.9975]\n",
            "Epoch 3/6: 100%|| 63/63 [07:44<00:00,  7.37s/it, loss=0.0007, acc=0.9955]\n",
            "Epoch 4/6: 100%|| 63/63 [07:44<00:00,  7.37s/it, loss=0.0003, acc=0.9990]\n",
            "Epoch 5/6: 100%|| 63/63 [07:44<00:00,  7.37s/it, loss=0.0002, acc=0.9990]\n",
            "Epoch 6/6: 100%|| 63/63 [07:44<00:00,  7.37s/it, loss=0.0003, acc=0.9975]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 2786.50s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 14.08s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.83      0.91       489\n",
            "   malicious       0.79      1.00      0.89       321\n",
            "\n",
            "    accuracy                           0.90       810\n",
            "   macro avg       0.90      0.92      0.90       810\n",
            "weighted avg       0.92      0.90      0.90       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              406               83\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.1697\n",
            "F1-score (weighted): 0.8986\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000 syscalls\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Sequence length: 2000 (1 embedding per syscall parameter)\n",
            "Input embedding dim: 384\n",
            "Model parameters: 578,626\n",
            "\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/6: 100%|| 63/63 [27:49<00:00, 26.49s/it, loss=0.0114, acc=0.8474]\n",
            "Epoch 2/6: 100%|| 63/63 [27:45<00:00, 26.44s/it, loss=0.0004, acc=0.9985]\n",
            "Epoch 3/6: 100%|| 63/63 [27:45<00:00, 26.43s/it, loss=0.0004, acc=0.9985]\n",
            "Epoch 4/6: 100%|| 63/63 [27:45<00:00, 26.43s/it, loss=0.0009, acc=0.9935]\n",
            "Epoch 5/6: 100%|| 63/63 [27:45<00:00, 26.44s/it, loss=0.0004, acc=0.9985]\n",
            "Epoch 6/6: 100%|| 63/63 [27:45<00:00, 26.43s/it, loss=0.0004, acc=0.9985]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 9996.82s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 24.92s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.82      0.90       489\n",
            "   malicious       0.78      1.00      0.88       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.91      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              399               90\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.1840\n",
            "F1-score (weighted): 0.8901\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes (window_size = number of syscalls)\n",
        "# With sentence embeddings, sequence length = window_size (instead of window_size * tokens_per_syscall)\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size} syscalls\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets with pre-computed embeddings\n",
        "    train_dataset = ParamsEmbeddingDataset(\n",
        "        train_files, param_to_embedding, window_size, EMBEDDING_DIM, PAD_EMBEDDING\n",
        "    )\n",
        "    test_dataset = ParamsEmbeddingDataset(\n",
        "        test_files, param_to_embedding, window_size, EMBEDDING_DIM, PAD_EMBEDDING\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    print(f\"Sequence length: {window_size} (1 embedding per syscall parameter)\")\n",
        "    print(f\"Input embedding dim: {EMBEDDING_DIM}\")\n",
        "    \n",
        "    # Create model - takes pre-computed embeddings as input\n",
        "    model = TransformerEncoderForEmbeddings(\n",
        "        input_dim=EMBEDDING_DIM, \n",
        "        max_len=window_size,\n",
        "        hidden_dim=128,\n",
        "        num_heads=4,\n",
        "        num_layers=2,\n",
        "        ff_dim=256\n",
        "    ).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True)\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            \n",
        "            # Update progress bar with current metrics\n",
        "            pbar.set_postfix({'loss': f'{total_loss/total:.4f}', 'acc': f'{correct/total:.4f}'})\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size (syscalls)': window_size,\n",
        "        'Seq Length': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
        "    \n",
        "    # Clear GPU memory between experiments\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5553dd28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS (Sentence Embeddings)\n",
            "================================================================================\n",
            " Window Size (syscalls)  Seq Length Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "                    250         250         0.9907              0.1800              0.8889          30.12          0.55\n",
            "                    500         500         0.9969              0.1043              0.9364         339.68          8.26\n",
            "                   1000        1000         1.0000              0.1697              0.8986        2786.50         14.08\n",
            "                   2000        2000         1.0000              0.1840              0.8901        9996.82         24.92\n",
            "\n",
            "Note: Using sentence embeddings reduces sequence length from\n",
            "window_size * ~13 tokens to just window_size embeddings,\n",
            "enabling larger window sizes within GPU memory constraints.\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS (Sentence Embeddings)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nNote: Using sentence embeddings reduces sequence length from\")\n",
        "print(\"window_size * ~13 tokens to just window_size embeddings,\")\n",
        "print(\"enabling larger window sizes within GPU memory constraints.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e09758",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a6003009",
      "metadata": {},
      "source": [
        "## Features: Syscalls + Return values + Parameters"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
