{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d7190ea8",
      "metadata": {},
      "source": [
        "## Feature: Syscall only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e65df671",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM with RBF Kernel - Syscall Classification\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "\n",
        "print(\"SVM with RBF Kernel - Syscall Classification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a008091d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n",
            "\n",
            "Vocabulary size: 80\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs(file_path):\n",
        "    \"\"\"Load syscalls grouped by run.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = df.groupby('run')['syscall'].apply(list).tolist()\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n",
        "\n",
        "# Collect all syscalls for building vocabulary\n",
        "all_syscalls = []\n",
        "for path, _ in train_files + test_files:\n",
        "    for run in load_runs(path):\n",
        "        all_syscalls.extend(run)\n",
        "\n",
        "# Build syscall encoder\n",
        "syscall_encoder = LabelEncoder()\n",
        "syscall_encoder.fit(all_syscalls)\n",
        "vocab_size = len(syscall_encoder.classes_)\n",
        "print(f\"\\nVocabulary size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a0d4dee5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using syscall frequency histogram as features\n"
          ]
        }
      ],
      "source": [
        "def extract_frequency_features(syscalls, encoder, max_len):\n",
        "    \"\"\"Extract syscall frequency features from a sequence.\"\"\"\n",
        "    # Truncate sequence to max_len\n",
        "    syscalls = syscalls[:max_len]\n",
        "    \n",
        "    # Encode syscalls\n",
        "    encoded = encoder.transform(syscalls)\n",
        "    \n",
        "    # Count frequencies\n",
        "    vocab_size = len(encoder.classes_)\n",
        "    freq = np.zeros(vocab_size)\n",
        "    for idx in encoded:\n",
        "        freq[idx] += 1\n",
        "    \n",
        "    # Normalize by total count\n",
        "    total = len(encoded)\n",
        "    if total > 0:\n",
        "        freq = freq / total\n",
        "    \n",
        "    return freq\n",
        "\n",
        "def prepare_dataset(file_label_pairs, encoder, max_len):\n",
        "    \"\"\"Prepare feature matrix and labels from file-label pairs.\"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    label_map = {'benign': 0, 'malicious': 1}\n",
        "    \n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs(path)\n",
        "        for run_syscalls in runs:\n",
        "            if len(run_syscalls) > 0:  # Need at least 1 syscall\n",
        "                features = extract_frequency_features(run_syscalls, encoder, max_len)\n",
        "                X.append(features)\n",
        "                y.append(label_map[label])\n",
        "    \n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "print(f\"Using syscall frequency histogram as features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e0fd41ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 80\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.04s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.02s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.82      0.90       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.90      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              402               87\n",
            "True: malicious             4              317\n",
            "\n",
            "Detection Rate: 0.9875\n",
            "False Positive Rate: 0.1779\n",
            "F1-score (weighted): 0.8889\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 80\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.04s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.02s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.81      0.89       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.89      0.90      0.88       810\n",
            "weighted avg       0.91      0.88      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              398               91\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1861\n",
            "F1-score (weighted): 0.8852\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 80\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.04s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.03s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.81      0.89       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.89      0.90      0.88       810\n",
            "weighted avg       0.91      0.88      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              397               92\n",
            "True: malicious             2              319\n",
            "\n",
            "Detection Rate: 0.9938\n",
            "False Positive Rate: 0.1881\n",
            "F1-score (weighted): 0.8852\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 80\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.04s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.02s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.81      0.89       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.88      0.90      0.88       810\n",
            "weighted avg       0.91      0.88      0.88       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              397               92\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1881\n",
            "F1-score (weighted): 0.8840\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Prepare datasets\n",
        "    X_train, y_train = prepare_dataset(train_files, syscall_encoder, window_size)\n",
        "    X_test, y_test = prepare_dataset(test_files, syscall_encoder, window_size)\n",
        "    \n",
        "    print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "    print(f\"Feature dimension: {X_train.shape[1]}\")\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Create SVM model with RBF kernel\n",
        "    model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining SVM with RBF kernel...\")\n",
        "    train_start_time = time.time()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bb043b69",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.9875              0.1779              0.8889           0.04          0.02\n",
            "         500         0.9907              0.1861              0.8852           0.04          0.02\n",
            "        1000         0.9938              0.1881              0.8852           0.04          0.03\n",
            "        2000         0.9907              0.1881              0.8840           0.04          0.02\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73ffa0b",
      "metadata": {},
      "source": [
        "## Feature: Return values only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5eb73d01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM with RBF Kernel - Return Value Classification\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "\n",
        "print(\"SVM with RBF Kernel - Return Value Classification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "71d04033",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n",
            "\n",
            "Vocabulary size: 42585\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_retval(file_path):\n",
        "    \"\"\"Load return values grouped by run.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = df.groupby('run')['Ret'].apply(list).tolist()\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_retval(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n",
        "\n",
        "# Collect all return values for building vocabulary\n",
        "all_retvals = []\n",
        "for path, _ in train_files + test_files:\n",
        "    for run in load_runs_retval(path):\n",
        "        all_retvals.extend(run)\n",
        "\n",
        "# Build return value encoder\n",
        "retval_encoder = LabelEncoder()\n",
        "retval_encoder.fit(all_retvals)\n",
        "vocab_size = len(retval_encoder.classes_)\n",
        "print(f\"\\nVocabulary size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0eaa64cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using return value frequency histogram as features\n"
          ]
        }
      ],
      "source": [
        "def extract_frequency_features_retval(retvals, encoder, max_len):\n",
        "    \"\"\"Extract return value frequency features from a sequence.\"\"\"\n",
        "    # Truncate sequence to max_len\n",
        "    retvals = retvals[:max_len]\n",
        "    \n",
        "    # Encode return values\n",
        "    encoded = encoder.transform(retvals)\n",
        "    \n",
        "    # Count frequencies\n",
        "    vocab_size = len(encoder.classes_)\n",
        "    freq = np.zeros(vocab_size)\n",
        "    for idx in encoded:\n",
        "        freq[idx] += 1\n",
        "    \n",
        "    # Normalize by total count\n",
        "    total = len(encoded)\n",
        "    if total > 0:\n",
        "        freq = freq / total\n",
        "    \n",
        "    return freq\n",
        "\n",
        "def prepare_dataset_retval(file_label_pairs, encoder, max_len):\n",
        "    \"\"\"Prepare feature matrix and labels from file-label pairs.\"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    label_map = {'benign': 0, 'malicious': 1}\n",
        "    \n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_retval(path)\n",
        "        for run_retvals in runs:\n",
        "            if len(run_retvals) > 0:  # Need at least 1 return value\n",
        "                features = extract_frequency_features_retval(run_retvals, encoder, max_len)\n",
        "                X.append(features)\n",
        "                y.append(label_map[label])\n",
        "    \n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "print(f\"Using return value frequency histogram as features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "50fe46f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 42585\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 16.80s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 10.77s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.63      0.18      0.28       489\n",
            "   malicious       0.40      0.84      0.54       321\n",
            "\n",
            "    accuracy                           0.44       810\n",
            "   macro avg       0.52      0.51      0.41       810\n",
            "weighted avg       0.54      0.44      0.38       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign               88              401\n",
            "True: malicious            52              269\n",
            "\n",
            "Detection Rate: 0.8380\n",
            "False Positive Rate: 0.8200\n",
            "F1-score (weighted): 0.3841\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 42585\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 27.43s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 19.39s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.86      0.52      0.65       489\n",
            "   malicious       0.54      0.87      0.67       321\n",
            "\n",
            "    accuracy                           0.66       810\n",
            "   macro avg       0.70      0.69      0.66       810\n",
            "weighted avg       0.73      0.66      0.66       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              256              233\n",
            "True: malicious            43              278\n",
            "\n",
            "Detection Rate: 0.8660\n",
            "False Positive Rate: 0.4765\n",
            "F1-score (weighted): 0.6571\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 42585\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 38.30s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 27.28s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.64      0.25      0.36       489\n",
            "   malicious       0.41      0.78      0.53       321\n",
            "\n",
            "    accuracy                           0.46       810\n",
            "   macro avg       0.52      0.52      0.45       810\n",
            "weighted avg       0.54      0.46      0.43       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              122              367\n",
            "True: malicious            70              251\n",
            "\n",
            "Detection Rate: 0.7819\n",
            "False Positive Rate: 0.7505\n",
            "F1-score (weighted): 0.4282\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 42585\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 36.73s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 26.17s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.27      0.13      0.18       489\n",
            "   malicious       0.26      0.45      0.33       321\n",
            "\n",
            "    accuracy                           0.26       810\n",
            "   macro avg       0.26      0.29      0.25       810\n",
            "weighted avg       0.26      0.26      0.24       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign               64              425\n",
            "True: malicious           175              146\n",
            "\n",
            "Detection Rate: 0.4548\n",
            "False Positive Rate: 0.8691\n",
            "F1-score (weighted): 0.2359\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Prepare datasets\n",
        "    X_train, y_train = prepare_dataset_retval(train_files, retval_encoder, window_size)\n",
        "    X_test, y_test = prepare_dataset_retval(test_files, retval_encoder, window_size)\n",
        "    \n",
        "    print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "    print(f\"Feature dimension: {X_train.shape[1]}\")\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Create SVM model with RBF kernel\n",
        "    model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining SVM with RBF kernel...\")\n",
        "    train_start_time = time.time()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5dd1ff52",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.8380              0.8200              0.3841          16.80         10.77\n",
            "         500         0.8660              0.4765              0.6571          27.43         19.39\n",
            "        1000         0.7819              0.7505              0.4282          38.30         27.28\n",
            "        2000         0.4548              0.8691              0.2359          36.73         26.17\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c45a85",
      "metadata": {},
      "source": [
        "## Feature: Parameters only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1db07b05",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adil-bb/anaconda3/envs/pt-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM with RBF Kernel - Parameters Classification (Sentence Embeddings)\n",
            "Loading sentence transformer model...\n",
            "Sentence embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "\n",
        "print(\"SVM with RBF Kernel - Parameters Classification (Sentence Embeddings)\")\n",
        "\n",
        "# Load sentence transformer model for semantic embeddings\n",
        "print(\"Loading sentence transformer model...\")\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
        "EMBEDDING_DIM = sentence_model.get_sentence_embedding_dimension()\n",
        "print(f\"Sentence embedding dimension: {EMBEDDING_DIM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a7e36c89",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_params_raw(file_path):\n",
        "    \"\"\"Load raw parameter strings grouped by run (list of param strings per run).\n",
        "    \n",
        "    Returns list of runs, where each run is a list of parameter strings (one per syscall).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = []\n",
        "    for run_id, group in df.groupby('run'):\n",
        "        # Keep parameters as list of strings (one per syscall)\n",
        "        run_params = group['parameters'].tolist()\n",
        "        runs.append(run_params)\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_params_raw(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "defb8c2d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unique parameter strings...\n",
            "Unique parameter strings: 266019\n",
            "Computing sentence embeddings (this may take a few minutes)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1040/1040 [19:43<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings computed. Shape per embedding: 384\n"
          ]
        }
      ],
      "source": [
        "# Pre-compute sentence embeddings for all unique parameter strings\n",
        "print(\"Collecting unique parameter strings...\")\n",
        "\n",
        "unique_params = set()\n",
        "for path, _ in train_files + test_files:\n",
        "    for run_params in load_runs_params_raw(path):\n",
        "        for param_str in run_params:\n",
        "            # Convert to string and handle NaN\n",
        "            if pd.isna(param_str):\n",
        "                unique_params.add('<EMPTY>')\n",
        "            else:\n",
        "                unique_params.add(str(param_str))\n",
        "\n",
        "unique_params = list(unique_params)\n",
        "print(f\"Unique parameter strings: {len(unique_params)}\")\n",
        "\n",
        "# Compute embeddings for all unique strings in batches\n",
        "print(\"Computing sentence embeddings (this may take a few minutes)...\")\n",
        "param_embeddings = sentence_model.encode(\n",
        "    unique_params, \n",
        "    show_progress_bar=True, \n",
        "    batch_size=256,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "# Create a mapping from parameter string to embedding\n",
        "param_to_embedding = {param: emb for param, emb in zip(unique_params, param_embeddings)}\n",
        "print(f\"Embeddings computed. Shape per embedding: {EMBEDDING_DIM}\")\n",
        "\n",
        "# Create a zero embedding for padding\n",
        "PAD_EMBEDDING = np.zeros(EMBEDDING_DIM, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a0a28473",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using sentence embeddings with mean pooling as features\n",
            "Feature dimension: 384\n"
          ]
        }
      ],
      "source": [
        "def extract_sentence_embedding_features(run_params, param_to_embedding, pad_embedding, window_size):\n",
        "    \"\"\"Extract aggregated sentence embedding features from a run.\n",
        "    \n",
        "    Uses mean pooling over all parameter embeddings in the window to create\n",
        "    a fixed-size feature vector (384 dimensions).\n",
        "    \n",
        "    Args:\n",
        "        run_params: List of parameter strings (one per syscall) for a run\n",
        "        param_to_embedding: Dict mapping parameter strings to embeddings\n",
        "        pad_embedding: Zero embedding for missing/empty parameters\n",
        "        window_size: Maximum number of syscalls to consider\n",
        "    \n",
        "    Returns:\n",
        "        384-dimensional feature vector (mean of all embeddings)\n",
        "    \"\"\"\n",
        "    # Take first window_size syscalls\n",
        "    params_to_use = run_params[:window_size]\n",
        "    \n",
        "    embeddings = []\n",
        "    for param_str in params_to_use:\n",
        "        if pd.isna(param_str):\n",
        "            key = '<EMPTY>'\n",
        "        else:\n",
        "            key = str(param_str)\n",
        "        embeddings.append(param_to_embedding.get(key, pad_embedding))\n",
        "    \n",
        "    if embeddings:\n",
        "        embeddings = np.array(embeddings)\n",
        "        # Mean pooling across all syscall parameter embeddings\n",
        "        return embeddings.mean(axis=0)  # Returns 384-dim vector\n",
        "    return pad_embedding\n",
        "\n",
        "def prepare_dataset_params(file_label_pairs, param_to_embedding, pad_embedding, window_size):\n",
        "    \"\"\"Prepare feature matrix and labels using sentence embeddings.\"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    label_map = {'benign': 0, 'malicious': 1}\n",
        "    \n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_params_raw(path)\n",
        "        for run_params in runs:\n",
        "            if len(run_params) > 0:  # Need at least 1 syscall\n",
        "                features = extract_sentence_embedding_features(\n",
        "                    run_params, param_to_embedding, pad_embedding, window_size\n",
        "                )\n",
        "                X.append(features)\n",
        "                y.append(label_map[label])\n",
        "    \n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "print(f\"Using sentence embeddings with mean pooling as features\")\n",
        "print(f\"Feature dimension: {EMBEDDING_DIM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aa02840a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 384\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.03s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.02s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.98      0.82      0.89       489\n",
            "   malicious       0.78      0.98      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.88      0.90      0.88       810\n",
            "weighted avg       0.90      0.88      0.88       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              401               88\n",
            "True: malicious             7              314\n",
            "\n",
            "Detection Rate: 0.9782\n",
            "False Positive Rate: 0.1800\n",
            "F1-score (weighted): 0.8840\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 384\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.02s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.01s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.81      0.89       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.88      0.90      0.88       810\n",
            "weighted avg       0.91      0.88      0.88       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              397               92\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1881\n",
            "F1-score (weighted): 0.8840\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 384\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.02s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.02s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.81      0.89       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.89      0.90      0.88       810\n",
            "weighted avg       0.91      0.88      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              397               92\n",
            "True: malicious             2              319\n",
            "\n",
            "Detection Rate: 0.9938\n",
            "False Positive Rate: 0.1881\n",
            "F1-score (weighted): 0.8852\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Feature dimension: 384\n",
            "\n",
            "Training SVM with RBF kernel...\n",
            "Training time: 0.02s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.02s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.81      0.89       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.88       810\n",
            "   macro avg       0.89      0.90      0.88       810\n",
            "weighted avg       0.91      0.88      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              397               92\n",
            "True: malicious             2              319\n",
            "\n",
            "Detection Rate: 0.9938\n",
            "False Positive Rate: 0.1881\n",
            "F1-score (weighted): 0.8852\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Prepare datasets\n",
        "    X_train, y_train = prepare_dataset_params(train_files, param_to_embedding, PAD_EMBEDDING, window_size)\n",
        "    X_test, y_test = prepare_dataset_params(test_files, param_to_embedding, PAD_EMBEDDING, window_size)\n",
        "    \n",
        "    print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "    print(f\"Feature dimension: {X_train.shape[1]}\")\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Create SVM model with RBF kernel\n",
        "    model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining SVM with RBF kernel...\")\n",
        "    train_start_time = time.time()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "31ce3388",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS (Sentence Embeddings)\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.9782              0.1800              0.8840           0.03          0.02\n",
            "         500         0.9907              0.1881              0.8840           0.02          0.01\n",
            "        1000         0.9938              0.1881              0.8852           0.02          0.02\n",
            "        2000         0.9938              0.1881              0.8852           0.02          0.02\n",
            "\n",
            "Note: Using sentence embeddings reduces feature dimension from\n",
            "131k+ token frequencies to just 384 semantic embedding dimensions.\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS (Sentence Embeddings)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nNote: Using sentence embeddings reduces feature dimension from\")\n",
        "print(\"131k+ token frequencies to just 384 semantic embedding dimensions.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pt-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
