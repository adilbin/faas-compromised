{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fbe2e3c0",
      "metadata": {},
      "source": [
        "## Feature: Syscall only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b2c30a72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "# WINDOW_SIZES = [500]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "1831628e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n",
            "\n",
            "Vocabulary size: 81 (including PAD)\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs(file_path):\n",
        "    \"\"\"Load syscalls grouped by run.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = df.groupby('run')['syscall'].apply(list).tolist()\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n",
        "\n",
        "# Collect all syscalls for building vocabulary\n",
        "all_syscalls = []\n",
        "for path, _ in train_files + test_files:\n",
        "    for run in load_runs(path):\n",
        "        all_syscalls.extend(run)\n",
        "\n",
        "# Build syscall encoder (add PAD token at index 0)\n",
        "syscall_encoder = LabelEncoder()\n",
        "syscall_encoder.fit(all_syscalls)\n",
        "vocab_size = len(syscall_encoder.classes_) + 1  # +1 for PAD token\n",
        "PAD_IDX = 0\n",
        "print(f\"\\nVocabulary size: {vocab_size} (including PAD)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0ba47887",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SyscallDataset(Dataset):\n",
        "    def __init__(self, file_label_pairs, encoder, max_len):\n",
        "        self.sequences = []\n",
        "        self.labels = []\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs(path)\n",
        "            for run_syscalls in runs:\n",
        "                # Encode syscalls (+1 to reserve 0 for PAD)\n",
        "                encoded = encoder.transform(run_syscalls) + 1\n",
        "                \n",
        "                # Truncate or pad to max_len\n",
        "                if len(encoded) > max_len:\n",
        "                    encoded = encoded[:max_len]\n",
        "                else:\n",
        "                    encoded = np.pad(encoded, (0, max_len - len(encoded)), constant_values=PAD_IDX)\n",
        "                \n",
        "                self.sequences.append(encoded)\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.sequences = np.array(self.sequences)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.sequences[idx], dtype=torch.long),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d7341005",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=64, num_filters=64, kernel_sizes=[3, 5, 7]):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embed_dim, num_filters, k, padding=k//2)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(num_filters * len(kernel_sizes), 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
        "        x = x.permute(0, 2, 1)  # (batch, embed_dim, seq_len)\n",
        "        \n",
        "        conv_outs = []\n",
        "        for conv in self.convs:\n",
        "            c = torch.relu(conv(x))\n",
        "            c = torch.max(c, dim=2)[0]  # Global max pooling\n",
        "            conv_outs.append(c)\n",
        "        \n",
        "        x = torch.cat(conv_outs, dim=1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4a33516f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1934, Acc: 0.9235\n",
            "Epoch 5/20 - Loss: 0.0071, Acc: 0.9965\n",
            "Epoch 10/20 - Loss: 0.0017, Acc: 0.9995\n",
            "Epoch 15/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Training time: 9.03s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.07s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.82      0.90       489\n",
            "   malicious       0.78      0.99      0.87       321\n",
            "\n",
            "    accuracy                           0.89       810\n",
            "   macro avg       0.89      0.90      0.89       810\n",
            "weighted avg       0.91      0.89      0.89       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              400               89\n",
            "True: malicious             3              318\n",
            "\n",
            "Detection Rate: 0.9907\n",
            "False Positive Rate: 0.1820\n",
            "F1-score (weighted): 0.8877\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1487, Acc: 0.9416\n",
            "Epoch 5/20 - Loss: 0.0003, Acc: 1.0000\n",
            "Epoch 10/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Training time: 14.67s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.10s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.97      0.98       489\n",
            "   malicious       0.95      1.00      0.97       321\n",
            "\n",
            "    accuracy                           0.98       810\n",
            "   macro avg       0.98      0.98      0.98       810\n",
            "weighted avg       0.98      0.98      0.98       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              473               16\n",
            "True: malicious             1              320\n",
            "\n",
            "Detection Rate: 0.9969\n",
            "False Positive Rate: 0.0327\n",
            "F1-score (weighted): 0.9791\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1804, Acc: 0.9225\n",
            "Epoch 5/20 - Loss: 0.0004, Acc: 1.0000\n",
            "Epoch 10/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Training time: 26.58s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.18s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.93      0.96       489\n",
            "   malicious       0.90      1.00      0.95       321\n",
            "\n",
            "    accuracy                           0.96       810\n",
            "   macro avg       0.95      0.97      0.96       810\n",
            "weighted avg       0.96      0.96      0.96       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              455               34\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.0695\n",
            "F1-score (weighted): 0.9583\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1542, Acc: 0.9391\n",
            "Epoch 5/20 - Loss: 0.0010, Acc: 1.0000\n",
            "Epoch 10/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Training time: 184.97s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 3.61s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.97      0.98       489\n",
            "   malicious       0.96      1.00      0.98       321\n",
            "\n",
            "    accuracy                           0.98       810\n",
            "   macro avg       0.98      0.98      0.98       810\n",
            "weighted avg       0.98      0.98      0.98       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              474               15\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.0307\n",
            "F1-score (weighted): 0.9815\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = SyscallDataset(train_files, syscall_encoder, window_size)\n",
        "    test_dataset = SyscallDataset(test_files, syscall_encoder, window_size)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = CNN1D(vocab_size).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cb1e86d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.9907              0.1820              0.8877           9.03          0.07\n",
            "         500         0.9969              0.0327              0.9791          14.67          0.10\n",
            "        1000         1.0000              0.0695              0.9583          26.58          0.18\n",
            "        2000         1.0000              0.0307              0.9815         184.97          3.61\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c0f5d21",
      "metadata": {},
      "source": [
        "## Feature: Return values only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "48dba05e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9db58dfd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n",
            "\n",
            "Vocabulary size: 42586 (including PAD)\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_retval(file_path):\n",
        "    \"\"\"Load return values grouped by run.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = df.groupby('run')['Ret'].apply(list).tolist()\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_retval(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n",
        "\n",
        "# Collect all return values for building vocabulary\n",
        "all_retvals = []\n",
        "for path, _ in train_files + test_files:\n",
        "    for run in load_runs_retval(path):\n",
        "        all_retvals.extend(run)\n",
        "\n",
        "# Build return value encoder (add PAD token at index 0)\n",
        "retval_encoder = LabelEncoder()\n",
        "retval_encoder.fit(all_retvals)\n",
        "vocab_size = len(retval_encoder.classes_) + 1  # +1 for PAD token\n",
        "PAD_IDX = 0\n",
        "print(f\"\\nVocabulary size: {vocab_size} (including PAD)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e44199d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RetvalDataset(Dataset):\n",
        "    def __init__(self, file_label_pairs, encoder, max_len):\n",
        "        self.sequences = []\n",
        "        self.labels = []\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs_retval(path)\n",
        "            for run_retvals in runs:\n",
        "                # Encode return values (+1 to reserve 0 for PAD)\n",
        "                encoded = encoder.transform(run_retvals) + 1\n",
        "                \n",
        "                # Truncate or pad to max_len\n",
        "                if len(encoded) > max_len:\n",
        "                    encoded = encoded[:max_len]\n",
        "                else:\n",
        "                    encoded = np.pad(encoded, (0, max_len - len(encoded)), constant_values=PAD_IDX)\n",
        "                \n",
        "                self.sequences.append(encoded)\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.sequences = np.array(self.sequences)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.sequences[idx], dtype=torch.long),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4d8007e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=64, num_filters=64, kernel_sizes=[3, 5, 7]):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embed_dim, num_filters, k, padding=k//2)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(num_filters * len(kernel_sizes), 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
        "        x = x.permute(0, 2, 1)  # (batch, embed_dim, seq_len)\n",
        "        \n",
        "        conv_outs = []\n",
        "        for conv in self.convs:\n",
        "            c = torch.relu(conv(x))\n",
        "            c = torch.max(c, dim=2)[0]  # Global max pooling\n",
        "            conv_outs.append(c)\n",
        "        \n",
        "        x = torch.cat(conv_outs, dim=1)\n",
        "        return self.fc(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4292e9fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 250\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.2172, Acc: 0.9129\n",
            "Epoch 5/20 - Loss: 0.0023, Acc: 0.9995\n",
            "Epoch 10/20 - Loss: 0.0004, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0002, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Training time: 83.13s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.26s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.93      0.96      0.94       489\n",
            "   malicious       0.93      0.88      0.91       321\n",
            "\n",
            "    accuracy                           0.93       810\n",
            "   macro avg       0.93      0.92      0.93       810\n",
            "weighted avg       0.93      0.93      0.93       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              469               20\n",
            "True: malicious            37              284\n",
            "\n",
            "Detection Rate: 0.8847\n",
            "False Positive Rate: 0.0409\n",
            "F1-score (weighted): 0.9293\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 500\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1945, Acc: 0.9225\n",
            "Epoch 5/20 - Loss: 0.0010, Acc: 1.0000\n",
            "Epoch 10/20 - Loss: 0.0002, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Training time: 140.61s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.43s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      1.00      1.00       489\n",
            "   malicious       1.00      1.00      1.00       321\n",
            "\n",
            "    accuracy                           1.00       810\n",
            "   macro avg       1.00      1.00      1.00       810\n",
            "weighted avg       1.00      1.00      1.00       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              488                1\n",
            "True: malicious             1              320\n",
            "\n",
            "Detection Rate: 0.9969\n",
            "False Positive Rate: 0.0020\n",
            "F1-score (weighted): 0.9975\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 1000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1877, Acc: 0.9335\n",
            "Epoch 5/20 - Loss: 0.0040, Acc: 0.9990\n",
            "Epoch 10/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Training time: 232.78s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 0.74s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.95      0.97       489\n",
            "   malicious       0.92      1.00      0.96       321\n",
            "\n",
            "    accuracy                           0.97       810\n",
            "   macro avg       0.96      0.97      0.97       810\n",
            "weighted avg       0.97      0.97      0.97       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              463               26\n",
            "True: malicious             1              320\n",
            "\n",
            "Detection Rate: 0.9969\n",
            "False Positive Rate: 0.0532\n",
            "F1-score (weighted): 0.9669\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "Training...\n",
            "Epoch 1/20 - Loss: 0.1980, Acc: 0.9265\n",
            "Epoch 5/20 - Loss: 0.0005, Acc: 1.0000\n",
            "Epoch 10/20 - Loss: 0.0002, Acc: 1.0000\n",
            "Epoch 15/20 - Loss: 0.0001, Acc: 1.0000\n",
            "Epoch 20/20 - Loss: 0.0000, Acc: 1.0000\n",
            "Training time: 527.77s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 3.24s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.91      0.95       489\n",
            "   malicious       0.87      1.00      0.93       321\n",
            "\n",
            "    accuracy                           0.94       810\n",
            "   macro avg       0.94      0.95      0.94       810\n",
            "weighted avg       0.95      0.94      0.94       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              443               46\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.0941\n",
            "F1-score (weighted): 0.9437\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = RetvalDataset(train_files, retval_encoder, window_size)\n",
        "    test_dataset = RetvalDataset(test_files, retval_encoder, window_size)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = CNN1D(vocab_size).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8d7f6c86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.8847              0.0409              0.9293          83.13          0.26\n",
            "         500         0.9969              0.0020              0.9975         140.61          0.43\n",
            "        1000         0.9969              0.0532              0.9669         232.78          0.74\n",
            "        2000         1.0000              0.0941              0.9437         527.77          3.24\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f24a958",
      "metadata": {},
      "source": [
        "## Feature: Parameters only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "42153dfe",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adil-bb/anaconda3/envs/pt-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Loading sentence transformer model...\n",
            "Sentence embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [2000]  # Different sliding window lengths to test\n",
        "# WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Load sentence transformer model for semantic embeddings\n",
        "print(\"Loading sentence transformer model...\")\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
        "EMBEDDING_DIM = sentence_model.get_sentence_embedding_dimension()\n",
        "print(f\"Sentence embedding dimension: {EMBEDDING_DIM}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ff7fc27e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_params_raw(file_path):\n",
        "    \"\"\"Load raw parameter strings grouped by run (list of param strings per run).\n",
        "    \n",
        "    Returns list of runs, where each run is a list of parameter strings (one per syscall).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = []\n",
        "    for run_id, group in df.groupby('run'):\n",
        "        # Keep parameters as list of strings (one per syscall)\n",
        "        run_params = group['parameters'].tolist()\n",
        "        runs.append(run_params)\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_params_raw(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c38d9742",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unique parameter strings...\n",
            "Unique parameter strings: 266019\n",
            "Computing sentence embeddings (this may take a few minutes)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1040/1040 [19:58<00:00,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings computed. Shape per embedding: 384\n"
          ]
        }
      ],
      "source": [
        "# Pre-compute sentence embeddings for all unique parameter strings\n",
        "print(\"Collecting unique parameter strings...\")\n",
        "\n",
        "unique_params = set()\n",
        "for path, _ in train_files + test_files:\n",
        "    for run_params in load_runs_params_raw(path):\n",
        "        for param_str in run_params:\n",
        "            # Convert to string and handle NaN\n",
        "            if pd.isna(param_str):\n",
        "                unique_params.add('<EMPTY>')\n",
        "            else:\n",
        "                unique_params.add(str(param_str))\n",
        "\n",
        "unique_params = list(unique_params)\n",
        "print(f\"Unique parameter strings: {len(unique_params)}\")\n",
        "\n",
        "# Compute embeddings for all unique strings in batches\n",
        "print(\"Computing sentence embeddings (this may take a few minutes)...\")\n",
        "param_embeddings = sentence_model.encode(\n",
        "    unique_params, \n",
        "    show_progress_bar=True, \n",
        "    batch_size=256,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "# Create a mapping from parameter string to embedding\n",
        "param_to_embedding = {param: emb for param, emb in zip(unique_params, param_embeddings)}\n",
        "print(f\"Embeddings computed. Shape per embedding: {EMBEDDING_DIM}\")\n",
        "\n",
        "# Create a zero embedding for padding\n",
        "PAD_EMBEDDING = np.zeros(EMBEDDING_DIM, dtype=np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2ff85961",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ParamsEmbeddingDataset(Dataset):\n",
        "    \"\"\"Dataset that uses pre-computed sentence embeddings for parameter strings.\n",
        "    \n",
        "    Instead of tokenizing each parameter string into multiple tokens,\n",
        "    we embed each parameter string as a single vector using a sentence transformer.\n",
        "    This reduces sequence length from window_size * tokens_per_syscall to just window_size.\n",
        "    \"\"\"\n",
        "    def __init__(self, file_label_pairs, param_to_embedding, window_size, embed_dim, pad_embedding):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            file_label_pairs: List of (file_path, label) tuples\n",
        "            param_to_embedding: Dict mapping parameter strings to embeddings\n",
        "            window_size: Number of syscalls (parameter strings) to consider from each run\n",
        "            embed_dim: Dimension of sentence embeddings\n",
        "            pad_embedding: Zero embedding for padding\n",
        "        \"\"\"\n",
        "        self.embeddings = []\n",
        "        self.labels = []\n",
        "        self.window_size = window_size\n",
        "        self.embed_dim = embed_dim\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs_params_raw(path)\n",
        "            for run_params in runs:\n",
        "                # Take first window_size parameter strings from this run\n",
        "                params_to_use = run_params[:window_size]\n",
        "                \n",
        "                # Get embedding for each parameter string\n",
        "                run_embeddings = []\n",
        "                for param_str in params_to_use:\n",
        "                    if pd.isna(param_str):\n",
        "                        key = '<EMPTY>'\n",
        "                    else:\n",
        "                        key = str(param_str)\n",
        "                    run_embeddings.append(param_to_embedding[key])\n",
        "                \n",
        "                # Pad to window_size if needed\n",
        "                while len(run_embeddings) < window_size:\n",
        "                    run_embeddings.append(pad_embedding)\n",
        "                \n",
        "                self.embeddings.append(np.array(run_embeddings, dtype=np.float32))\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.embeddings = np.array(self.embeddings)  # Shape: (num_samples, window_size, embed_dim)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.embeddings[idx], dtype=torch.float32),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "755f9de2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN1DForEmbeddings(nn.Module):\n",
        "    \"\"\"1D CNN that takes pre-computed embeddings as input.\n",
        "    \n",
        "    Unlike the standard version that has an embedding layer,\n",
        "    this version expects inputs to already be embedded (float tensors).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, num_filters=64, kernel_sizes=[3, 5, 7]):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(input_dim, num_filters, k, padding=k//2)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(num_filters * len(kernel_sizes), 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, seq_len, input_dim)\n",
        "        x = x.permute(0, 2, 1)  # (batch, input_dim, seq_len)\n",
        "        \n",
        "        conv_outs = []\n",
        "        for conv in self.convs:\n",
        "            c = torch.relu(conv(x))\n",
        "            c = torch.max(c, dim=2)[0]  # Global max pooling\n",
        "            conv_outs.append(c)\n",
        "        \n",
        "        x = torch.cat(conv_outs, dim=1)\n",
        "        return self.fc(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dba119cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000 syscalls\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "Sequence length: 2000 (1 embedding per syscall parameter)\n",
            "Input embedding dim: 384\n",
            "Model parameters: 381,314\n",
            "\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 63/63 [00:37<00:00,  1.70it/s, loss=0.0076, acc=0.9013]\n",
            "Epoch 2/20: 100%|██████████| 63/63 [00:42<00:00,  1.47it/s, loss=0.0003, acc=0.9985]\n",
            "Epoch 3/20: 100%|██████████| 63/63 [00:45<00:00,  1.38it/s, loss=0.0002, acc=0.9985]\n",
            "Epoch 4/20: 100%|██████████| 63/63 [00:45<00:00,  1.37it/s, loss=0.0001, acc=0.9990]\n",
            "Epoch 5/20: 100%|██████████| 63/63 [00:49<00:00,  1.27it/s, loss=0.0001, acc=0.9995]\n",
            "Epoch 6/20: 100%|██████████| 63/63 [00:49<00:00,  1.28it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 7/20: 100%|██████████| 63/63 [00:50<00:00,  1.25it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 8/20: 100%|██████████| 63/63 [00:53<00:00,  1.17it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 9/20: 100%|██████████| 63/63 [00:55<00:00,  1.14it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 10/20: 100%|██████████| 63/63 [00:54<00:00,  1.15it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 11/20: 100%|██████████| 63/63 [00:54<00:00,  1.16it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 12/20: 100%|██████████| 63/63 [00:56<00:00,  1.11it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 13/20: 100%|██████████| 63/63 [00:53<00:00,  1.17it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 14/20: 100%|██████████| 63/63 [00:54<00:00,  1.16it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 15/20: 100%|██████████| 63/63 [00:55<00:00,  1.14it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 16/20: 100%|██████████| 63/63 [00:54<00:00,  1.15it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 17/20: 100%|██████████| 63/63 [00:55<00:00,  1.13it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 18/20: 100%|██████████| 63/63 [00:55<00:00,  1.14it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 19/20: 100%|██████████| 63/63 [00:54<00:00,  1.16it/s, loss=0.0000, acc=1.0000]\n",
            "Epoch 20/20: 100%|██████████| 63/63 [00:56<00:00,  1.12it/s, loss=0.0000, acc=1.0000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1035.87s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 7.39s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.96      0.98       489\n",
            "   malicious       0.94      1.00      0.97       321\n",
            "\n",
            "    accuracy                           0.98       810\n",
            "   macro avg       0.97      0.98      0.98       810\n",
            "weighted avg       0.98      0.98      0.98       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              470               19\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.0389\n",
            "F1-score (weighted): 0.9766\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes (window_size = number of syscalls)\n",
        "# With sentence embeddings, sequence length = window_size (instead of window_size * tokens_per_syscall)\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size} syscalls\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets with pre-computed embeddings\n",
        "    train_dataset = ParamsEmbeddingDataset(\n",
        "        train_files, param_to_embedding, window_size, EMBEDDING_DIM, PAD_EMBEDDING\n",
        "    )\n",
        "    test_dataset = ParamsEmbeddingDataset(\n",
        "        test_files, param_to_embedding, window_size, EMBEDDING_DIM, PAD_EMBEDDING\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    print(f\"Sequence length: {window_size} (1 embedding per syscall parameter)\")\n",
        "    print(f\"Input embedding dim: {EMBEDDING_DIM}\")\n",
        "    \n",
        "    # Create model - takes pre-computed embeddings as input\n",
        "    model = CNN1DForEmbeddings(input_dim=EMBEDDING_DIM, num_filters=64).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True)\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            \n",
        "            # Update progress bar with current metrics\n",
        "            pbar.set_postfix({'loss': f'{total_loss/total:.4f}', 'acc': f'{correct/total:.4f}'})\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size (syscalls)': window_size,\n",
        "        'Seq Length': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels], columns=[f'Pred: {l}' for l in labels])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
        "    \n",
        "    # Clear GPU memory between experiments\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "811a5c49",
      "metadata": {},
      "source": [
        "#### Earlier results 250 -> 1000 window size\n",
        "\n",
        "```plaintext\n",
        "============================================================\n",
        "EXPERIMENT: Window Size = 250 syscalls\n",
        "============================================================\n",
        "Train samples: 1986, Test samples: 810\n",
        "Sequence length: 250 (1 embedding per syscall parameter)\n",
        "Input embedding dim: 384\n",
        "Model parameters: 381,314\n",
        "\n",
        "Training...\n",
        "Epoch 1/20: 100%|██████████| 63/63 [00:04<00:00, 13.63it/s, loss=0.0087, acc=0.8832]\n",
        "Epoch 2/20: 100%|██████████| 63/63 [00:05<00:00, 12.52it/s, loss=0.0007, acc=0.9955]\n",
        "Epoch 3/20: 100%|██████████| 63/63 [00:05<00:00, 11.98it/s, loss=0.0006, acc=0.9935]\n",
        "Epoch 4/20: 100%|██████████| 63/63 [00:05<00:00, 11.24it/s, loss=0.0004, acc=0.9945]\n",
        "Epoch 5/20: 100%|██████████| 63/63 [00:05<00:00, 10.65it/s, loss=0.0003, acc=0.9965]\n",
        "Epoch 6/20: 100%|██████████| 63/63 [00:06<00:00, 10.10it/s, loss=0.0002, acc=0.9970]\n",
        "Epoch 7/20: 100%|██████████| 63/63 [00:06<00:00,  9.90it/s, loss=0.0002, acc=0.9990]\n",
        "Epoch 8/20: 100%|██████████| 63/63 [00:06<00:00, 10.01it/s, loss=0.0002, acc=0.9985]\n",
        "Epoch 9/20: 100%|██████████| 63/63 [00:06<00:00,  9.65it/s, loss=0.0002, acc=0.9975]\n",
        "Epoch 10/20: 100%|██████████| 63/63 [00:06<00:00,  9.48it/s, loss=0.0001, acc=0.9995]\n",
        "Epoch 11/20: 100%|██████████| 63/63 [00:07<00:00,  8.87it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 12/20: 100%|██████████| 63/63 [00:07<00:00,  8.99it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 13/20: 100%|██████████| 63/63 [00:07<00:00,  8.97it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 14/20: 100%|██████████| 63/63 [00:06<00:00,  9.18it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 15/20: 100%|██████████| 63/63 [00:07<00:00,  8.81it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 16/20: 100%|██████████| 63/63 [00:07<00:00,  8.66it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 17/20: 100%|██████████| 63/63 [00:07<00:00,  8.78it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 18/20: 100%|██████████| 63/63 [00:07<00:00,  8.78it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 19/20: 100%|██████████| 63/63 [00:07<00:00,  8.81it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 20/20: 100%|██████████| 63/63 [00:07<00:00,  8.62it/s, loss=0.0000, acc=1.0000]\n",
        "Training time: 129.75s\n",
        "\n",
        "Evaluating...\n",
        "Test time: 0.86s\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      benign       0.99      0.95      0.97       489\n",
        "   malicious       0.93      0.99      0.96       321\n",
        "\n",
        "    accuracy                           0.97       810\n",
        "   macro avg       0.96      0.97      0.97       810\n",
        "weighted avg       0.97      0.97      0.97       810\n",
        "\n",
        "Confusion Matrix:\n",
        "                 Pred: benign  Pred: malicious\n",
        "True: benign              465               24\n",
        "True: malicious             3              318\n",
        "\n",
        "Detection Rate: 0.9907\n",
        "False Positive Rate: 0.0491\n",
        "F1-score (weighted): 0.9668\n",
        "\n",
        "============================================================\n",
        "...\n",
        "Input embedding dim: 384\n",
        "Model parameters: 381,314\n",
        "\n",
        "Training...\n",
        "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
        "Epoch 1/20: 100%|██████████| 63/63 [00:08<00:00,  7.22it/s, loss=0.0080, acc=0.8988]\n",
        "Epoch 2/20: 100%|██████████| 63/63 [00:10<00:00,  6.30it/s, loss=0.0004, acc=0.9980]\n",
        "Epoch 3/20: 100%|██████████| 63/63 [00:10<00:00,  5.85it/s, loss=0.0002, acc=0.9985]\n",
        "Epoch 4/20: 100%|██████████| 63/63 [00:11<00:00,  5.49it/s, loss=0.0001, acc=0.9985]\n",
        "Epoch 5/20: 100%|██████████| 63/63 [00:11<00:00,  5.43it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 6/20: 100%|██████████| 63/63 [00:12<00:00,  5.04it/s, loss=0.0000, acc=0.9995]\n",
        "Epoch 7/20: 100%|██████████| 63/63 [00:12<00:00,  4.89it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 8/20: 100%|██████████| 63/63 [00:12<00:00,  4.94it/s, loss=0.0001, acc=0.9995]\n",
        "Epoch 9/20: 100%|██████████| 63/63 [00:13<00:00,  4.68it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 10/20: 100%|██████████| 63/63 [00:13<00:00,  4.61it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 11/20: 100%|██████████| 63/63 [00:14<00:00,  4.47it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 12/20: 100%|██████████| 63/63 [00:13<00:00,  4.51it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 13/20: 100%|██████████| 63/63 [00:14<00:00,  4.48it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 14/20: 100%|██████████| 63/63 [00:13<00:00,  4.57it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 15/20: 100%|██████████| 63/63 [00:13<00:00,  4.52it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 16/20: 100%|██████████| 63/63 [00:14<00:00,  4.39it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 17/20: 100%|██████████| 63/63 [00:14<00:00,  4.46it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 18/20: 100%|██████████| 63/63 [00:14<00:00,  4.42it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 19/20: 100%|██████████| 63/63 [00:14<00:00,  4.44it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 20/20: 100%|██████████| 63/63 [00:13<00:00,  4.54it/s, loss=0.0000, acc=1.0000]\n",
        "Training time: 258.57s\n",
        "\n",
        "Evaluating...\n",
        "Test time: 1.69s\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      benign       1.00      0.99      1.00       489\n",
        "   malicious       0.99      1.00      0.99       321\n",
        "\n",
        "    accuracy                           1.00       810\n",
        "   macro avg       0.99      1.00      0.99       810\n",
        "weighted avg       1.00      1.00      1.00       810\n",
        "\n",
        "Confusion Matrix:\n",
        "                 Pred: benign  Pred: malicious\n",
        "True: benign              486                3\n",
        "True: malicious             1              320\n",
        "\n",
        "Detection Rate: 0.9969\n",
        "False Positive Rate: 0.0061\n",
        "F1-score (weighted): 0.9951\n",
        "\n",
        "============================================================\n",
        "...\n",
        "Input embedding dim: 384\n",
        "Model parameters: 381,314\n",
        "\n",
        "Training...\n",
        "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
        "Epoch 1/20: 100%|██████████| 63/63 [00:17<00:00,  3.67it/s, loss=0.0078, acc=0.8902]\n",
        "Epoch 2/20: 100%|██████████| 63/63 [00:21<00:00,  2.91it/s, loss=0.0003, acc=0.9985]\n",
        "Epoch 3/20: 100%|██████████| 63/63 [00:21<00:00,  2.88it/s, loss=0.0002, acc=0.9990]\n",
        "Epoch 4/20: 100%|██████████| 63/63 [00:23<00:00,  2.66it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 5/20: 100%|██████████| 63/63 [00:24<00:00,  2.53it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 6/20: 100%|██████████| 63/63 [00:25<00:00,  2.50it/s, loss=0.0000, acc=0.9995]\n",
        "Epoch 7/20: 100%|██████████| 63/63 [00:25<00:00,  2.49it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 8/20: 100%|██████████| 63/63 [00:26<00:00,  2.40it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 9/20: 100%|██████████| 63/63 [00:26<00:00,  2.39it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 10/20: 100%|██████████| 63/63 [00:26<00:00,  2.36it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 11/20: 100%|██████████| 63/63 [00:26<00:00,  2.35it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 12/20: 100%|██████████| 63/63 [00:26<00:00,  2.39it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 13/20: 100%|██████████| 63/63 [00:27<00:00,  2.31it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 14/20: 100%|██████████| 63/63 [00:27<00:00,  2.31it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 15/20: 100%|██████████| 63/63 [00:26<00:00,  2.40it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 16/20: 100%|██████████| 63/63 [00:26<00:00,  2.36it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 17/20: 100%|██████████| 63/63 [00:27<00:00,  2.33it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 18/20: 100%|██████████| 63/63 [00:27<00:00,  2.29it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 19/20: 100%|██████████| 63/63 [00:27<00:00,  2.33it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 20/20: 100%|██████████| 63/63 [00:27<00:00,  2.28it/s, loss=0.0000, acc=1.0000]\n",
        "Training time: 509.14s\n",
        "\n",
        "Evaluating...\n",
        "Test time: 3.33s\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      benign       1.00      0.96      0.98       489\n",
        "   malicious       0.94      1.00      0.97       321\n",
        "\n",
        "    accuracy                           0.97       810\n",
        "   macro avg       0.97      0.98      0.97       810\n",
        "weighted avg       0.97      0.97      0.97       810\n",
        "\n",
        "Confusion Matrix:\n",
        "                 Pred: benign  Pred: malicious\n",
        "True: benign              467               22\n",
        "True: malicious             0              321\n",
        "\n",
        "Detection Rate: 1.0000\n",
        "False Positive Rate: 0.0450\n",
        "F1-score (weighted): 0.9730\n",
        "\n",
        "============================================================\n",
        "EXPERIMENT: Window Size = 2000 syscalls\n",
        "============================================================\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "312c3402",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS (Sentence Embeddings)\n",
            "================================================================================\n",
            " Window Size (syscalls)  Seq Length Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "                    250         250         0.9907              0.0491              0.9668         129.75          0.86\n",
            "                    500         500         0.9969              0.0061              0.9951         258.57          1.69\n",
            "                   1000        1000         1.0000              0.0450              0.9730         509.14          3.33\n",
            "                   2000        2000         1.0000              0.0389              0.9766        1035.87          7.39\n",
            "\n",
            "Note: Using sentence embeddings reduces sequence length from\n",
            "window_size * ~13 tokens to just window_size embeddings,\n",
            "enabling larger window sizes within GPU memory constraints.\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS (Sentence Embeddings)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nNote: Using sentence embeddings reduces sequence length from\")\n",
        "print(\"window_size * ~13 tokens to just window_size embeddings,\")\n",
        "print(\"enabling larger window sizes within GPU memory constraints.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pt-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
