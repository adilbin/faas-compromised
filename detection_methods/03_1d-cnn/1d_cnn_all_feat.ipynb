{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# 1D CNN with All Features Combined\n",
        "\n",
        "This notebook implements a 1D CNN for syscall-based malware detection using **all features combined**:\n",
        "- **Syscall**: Categorical feature (embedded)\n",
        "- **Return Value (Ret)**: Categorical feature (embedded)\n",
        "- **Parameters**: Text feature (sentence transformer embeddings)\n",
        "\n",
        "The three feature representations are concatenated at each timestep to form a unified representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adil-bb/anaconda3/envs/pt-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Loading sentence transformer model...\n",
            "Parameter embedding dimension: 384\n",
            "Total combined embedding dimension: 448\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../configs')\n",
        "from config_loader import get_split_with_labels\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "SPLIT = '70'\n",
        "WINDOW_SIZES = [2000]  # Different sliding window lengths to test\n",
        "# WINDOW_SIZES = [250, 500, 1000, 2000]  # Different sliding window lengths to test\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Embedding dimensions\n",
        "SYSCALL_EMBED_DIM = 32\n",
        "RETVAL_EMBED_DIM = 32\n",
        "\n",
        "# Load sentence transformer model for parameter embeddings\n",
        "print(\"Loading sentence transformer model...\")\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
        "PARAM_EMBED_DIM = sentence_model.get_sentence_embedding_dimension()\n",
        "print(f\"Parameter embedding dimension: {PARAM_EMBED_DIM}\")\n",
        "print(f\"Total combined embedding dimension: {SYSCALL_EMBED_DIM + RETVAL_EMBED_DIM + PARAM_EMBED_DIM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "load_data",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 21, Test files: 9\n",
            "\n",
            "Training set:\n",
            "  Total runs: 1986\n",
            "  Benign runs: 1484\n",
            "  Malicious runs: 502\n",
            "\n",
            "Test set:\n",
            "  Total runs: 810\n",
            "  Benign runs: 489\n",
            "  Malicious runs: 321\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_files, test_files = get_split_with_labels(SPLIT)\n",
        "print(f\"Train files: {len(train_files)}, Test files: {len(test_files)}\")\n",
        "\n",
        "def load_runs_all_features(file_path):\n",
        "    \"\"\"Load all features (syscall, ret, parameters) grouped by run.\n",
        "    \n",
        "    Returns list of runs, where each run is a dict with:\n",
        "        - 'syscalls': list of syscall names\n",
        "        - 'retvals': list of return values\n",
        "        - 'params': list of parameter strings\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    runs = []\n",
        "    for run_id, group in df.groupby('run'):\n",
        "        run_data = {\n",
        "            'syscalls': group['syscall'].tolist(),\n",
        "            'retvals': group['Ret'].tolist(),\n",
        "            'params': group['parameters'].tolist()\n",
        "        }\n",
        "        runs.append(run_data)\n",
        "    return runs\n",
        "\n",
        "# Count runs per label for training and test sets\n",
        "def count_runs_per_label(file_label_pairs):\n",
        "    \"\"\"Count total runs per label.\"\"\"\n",
        "    counts = {'benign': 0, 'malicious': 0}\n",
        "    for path, label in file_label_pairs:\n",
        "        runs = load_runs_all_features(path)\n",
        "        counts[label] += len(runs)\n",
        "    return counts\n",
        "\n",
        "train_counts = count_runs_per_label(train_files)\n",
        "test_counts = count_runs_per_label(test_files)\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Total runs: {sum(train_counts.values())}\")\n",
        "print(f\"  Benign runs: {train_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {train_counts['malicious']}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Total runs: {sum(test_counts.values())}\")\n",
        "print(f\"  Benign runs: {test_counts['benign']}\")\n",
        "print(f\"  Malicious runs: {test_counts['malicious']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "build_encoders",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoders for syscalls and return values...\n",
            "Syscall vocabulary size: 81 (including PAD)\n",
            "Return value vocabulary size: 42586 (including PAD)\n",
            "\n",
            "Unique parameter strings: 266019\n"
          ]
        }
      ],
      "source": [
        "# Build encoders for syscalls and return values\n",
        "print(\"Building encoders for syscalls and return values...\")\n",
        "\n",
        "all_syscalls = []\n",
        "all_retvals = []\n",
        "all_params = set()\n",
        "\n",
        "for path, _ in train_files + test_files:\n",
        "    for run_data in load_runs_all_features(path):\n",
        "        all_syscalls.extend(run_data['syscalls'])\n",
        "        all_retvals.extend(run_data['retvals'])\n",
        "        for param in run_data['params']:\n",
        "            if pd.isna(param):\n",
        "                all_params.add('<EMPTY>')\n",
        "            else:\n",
        "                all_params.add(str(param))\n",
        "\n",
        "# Build syscall encoder\n",
        "syscall_encoder = LabelEncoder()\n",
        "syscall_encoder.fit(all_syscalls)\n",
        "syscall_vocab_size = len(syscall_encoder.classes_) + 1  # +1 for PAD token\n",
        "print(f\"Syscall vocabulary size: {syscall_vocab_size} (including PAD)\")\n",
        "\n",
        "# Build return value encoder\n",
        "retval_encoder = LabelEncoder()\n",
        "retval_encoder.fit(all_retvals)\n",
        "retval_vocab_size = len(retval_encoder.classes_) + 1  # +1 for PAD token\n",
        "print(f\"Return value vocabulary size: {retval_vocab_size} (including PAD)\")\n",
        "\n",
        "# PAD index for embeddings\n",
        "PAD_IDX = 0\n",
        "\n",
        "print(f\"\\nUnique parameter strings: {len(all_params)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "param_embeddings",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing sentence embeddings for parameters (this may take a few minutes)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1040/1040 [19:56<00:00,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter embeddings computed. Shape per embedding: 384\n"
          ]
        }
      ],
      "source": [
        "# Pre-compute sentence embeddings for all unique parameter strings\n",
        "print(\"Computing sentence embeddings for parameters (this may take a few minutes)...\")\n",
        "\n",
        "all_params_list = list(all_params)\n",
        "param_embeddings = sentence_model.encode(\n",
        "    all_params_list,\n",
        "    show_progress_bar=True,\n",
        "    batch_size=256,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "# Create a mapping from parameter string to embedding\n",
        "param_to_embedding = {param: emb for param, emb in zip(all_params_list, param_embeddings)}\n",
        "print(f\"Parameter embeddings computed. Shape per embedding: {PARAM_EMBED_DIM}\")\n",
        "\n",
        "# Create zero embedding for padding\n",
        "PAD_PARAM_EMBEDDING = np.zeros(PARAM_EMBED_DIM, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dataset_class",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AllFeaturesDataset(Dataset):\n",
        "    \"\"\"Dataset that combines syscall, return value, and parameter features.\n",
        "    \n",
        "    For each timestep, we have:\n",
        "    - Syscall index (to be embedded by the model)\n",
        "    - Return value index (to be embedded by the model)\n",
        "    - Parameter embedding (pre-computed sentence embedding)\n",
        "    \"\"\"\n",
        "    def __init__(self, file_label_pairs, syscall_encoder, retval_encoder, \n",
        "                 param_to_embedding, window_size, param_embed_dim, pad_param_embedding):\n",
        "        self.syscall_seqs = []\n",
        "        self.retval_seqs = []\n",
        "        self.param_embeddings = []\n",
        "        self.labels = []\n",
        "        label_map = {'benign': 0, 'malicious': 1}\n",
        "        \n",
        "        for path, label in file_label_pairs:\n",
        "            runs = load_runs_all_features(path)\n",
        "            for run_data in runs:\n",
        "                syscalls = run_data['syscalls']\n",
        "                retvals = run_data['retvals']\n",
        "                params = run_data['params']\n",
        "                \n",
        "                seq_len = min(len(syscalls), window_size)\n",
        "                \n",
        "                # Encode syscalls (+1 to reserve 0 for PAD)\n",
        "                encoded_syscalls = syscall_encoder.transform(syscalls[:seq_len]) + 1\n",
        "                if len(encoded_syscalls) < window_size:\n",
        "                    encoded_syscalls = np.pad(encoded_syscalls, \n",
        "                                              (0, window_size - len(encoded_syscalls)), \n",
        "                                              constant_values=PAD_IDX)\n",
        "                \n",
        "                # Encode return values (+1 to reserve 0 for PAD)\n",
        "                encoded_retvals = retval_encoder.transform(retvals[:seq_len]) + 1\n",
        "                if len(encoded_retvals) < window_size:\n",
        "                    encoded_retvals = np.pad(encoded_retvals, \n",
        "                                             (0, window_size - len(encoded_retvals)), \n",
        "                                             constant_values=PAD_IDX)\n",
        "                \n",
        "                # Get parameter embeddings\n",
        "                param_embs = []\n",
        "                for i in range(window_size):\n",
        "                    if i < len(params):\n",
        "                        param = params[i]\n",
        "                        if pd.isna(param):\n",
        "                            key = '<EMPTY>'\n",
        "                        else:\n",
        "                            key = str(param)\n",
        "                        param_embs.append(param_to_embedding[key])\n",
        "                    else:\n",
        "                        param_embs.append(pad_param_embedding)\n",
        "                \n",
        "                self.syscall_seqs.append(encoded_syscalls)\n",
        "                self.retval_seqs.append(encoded_retvals)\n",
        "                self.param_embeddings.append(np.array(param_embs, dtype=np.float32))\n",
        "                self.labels.append(label_map[label])\n",
        "        \n",
        "        self.syscall_seqs = np.array(self.syscall_seqs)\n",
        "        self.retval_seqs = np.array(self.retval_seqs)\n",
        "        self.param_embeddings = np.array(self.param_embeddings)\n",
        "        self.labels = np.array(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.tensor(self.syscall_seqs[idx], dtype=torch.long),\n",
        "            torch.tensor(self.retval_seqs[idx], dtype=torch.long),\n",
        "            torch.tensor(self.param_embeddings[idx], dtype=torch.float32),\n",
        "            torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "model_class",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN1DAllFeatures(nn.Module):\n",
        "    \"\"\"1D CNN that combines all features:\n",
        "    - Syscall embeddings (learned)\n",
        "    - Return value embeddings (learned)\n",
        "    - Parameter embeddings (pre-computed sentence embeddings)\n",
        "    \n",
        "    All three are concatenated at each timestep before being fed to the CNN.\n",
        "    \"\"\"\n",
        "    def __init__(self, syscall_vocab_size, retval_vocab_size, \n",
        "                 syscall_embed_dim, retval_embed_dim, param_embed_dim,\n",
        "                 num_filters=64, kernel_sizes=[3, 5, 7]):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Embedding layers for categorical features\n",
        "        self.syscall_embedding = nn.Embedding(syscall_vocab_size, syscall_embed_dim, padding_idx=PAD_IDX)\n",
        "        self.retval_embedding = nn.Embedding(retval_vocab_size, retval_embed_dim, padding_idx=PAD_IDX)\n",
        "        \n",
        "        # Total input dimension after concatenation\n",
        "        total_embed_dim = syscall_embed_dim + retval_embed_dim + param_embed_dim\n",
        "        \n",
        "        # 1D Convolution layers\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(total_embed_dim, num_filters, k, padding=k//2)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(num_filters * len(kernel_sizes), 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    \n",
        "    def forward(self, syscalls, retvals, param_embs):\n",
        "        # Embed categorical features\n",
        "        syscall_emb = self.syscall_embedding(syscalls)  # (batch, seq_len, syscall_embed_dim)\n",
        "        retval_emb = self.retval_embedding(retvals)      # (batch, seq_len, retval_embed_dim)\n",
        "        \n",
        "        # param_embs already has shape (batch, seq_len, param_embed_dim)\n",
        "        \n",
        "        # Concatenate all embeddings\n",
        "        x = torch.cat([syscall_emb, retval_emb, param_embs], dim=2)  # (batch, seq_len, total_embed_dim)\n",
        "        x = x.permute(0, 2, 1)  # (batch, total_embed_dim, seq_len)\n",
        "        \n",
        "        # Apply convolutions with global max pooling\n",
        "        conv_outs = []\n",
        "        for conv in self.convs:\n",
        "            c = torch.relu(conv(x))\n",
        "            c = torch.max(c, dim=2)[0]  # Global max pooling\n",
        "            conv_outs.append(c)\n",
        "        \n",
        "        x = torch.cat(conv_outs, dim=1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6ce9fe",
      "metadata": {},
      "source": [
        "### Results for 250, 500, and 1000 window size\n",
        "```plaintext\n",
        "============================================================\n",
        "EXPERIMENT: Window Size = 250\n",
        "============================================================\n",
        "Train samples: 1986, Test samples: 810\n",
        "\n",
        "--- Input Shapes ---\n",
        "  Syscall input shape:   (batch_size, 250)\n",
        "  Retval input shape:    (batch_size, 250)\n",
        "  Param emb input shape: (batch_size, 250, 384)\n",
        "  After embedding concat: (batch_size, 250, 448)\n",
        "\n",
        "--- Model Architecture & Parameters ---\n",
        "  syscall_embedding.weight: [81, 32] = 2,592 params\n",
        "  retval_embedding.weight: [42586, 32] = 1,362,752 params\n",
        "  convs.0.weight: [64, 448, 3] = 86,016 params\n",
        "  convs.0.bias: [64] = 64 params\n",
        "  convs.1.weight: [64, 448, 5] = 143,360 params\n",
        "  convs.1.bias: [64] = 64 params\n",
        "  convs.2.weight: [64, 448, 7] = 200,704 params\n",
        "  convs.2.bias: [64] = 64 params\n",
        "  fc.0.weight: [64, 192] = 12,288 params\n",
        "  fc.0.bias: [64] = 64 params\n",
        "  fc.3.weight: [2, 64] = 128 params\n",
        "  fc.3.bias: [2] = 2 params\n",
        "  ──────────────────────────────────────────────────\n",
        "  Total parameters:     1,808,098\n",
        "  Trainable parameters: 1,808,098\n",
        "\n",
        "Training...\n",
        "Epoch 1/20: 100%|██████████| 63/63 [00:08<00:00,  7.48it/s, loss=0.0061, acc=0.9285]\n",
        "Epoch 2/20: 100%|██████████| 63/63 [00:09<00:00,  6.68it/s, loss=0.0004, acc=0.9950]\n",
        "Epoch 3/20: 100%|██████████| 63/63 [00:09<00:00,  6.51it/s, loss=0.0003, acc=0.9960]\n",
        "Epoch 4/20: 100%|██████████| 63/63 [00:09<00:00,  6.35it/s, loss=0.0001, acc=0.9980]\n",
        "Epoch 5/20: 100%|██████████| 63/63 [00:10<00:00,  6.22it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 6/20: 100%|██████████| 63/63 [00:10<00:00,  6.04it/s, loss=0.0001, acc=0.9990]\n",
        "Epoch 7/20: 100%|██████████| 63/63 [00:10<00:00,  6.00it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 8/20: 100%|██████████| 63/63 [00:10<00:00,  6.06it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 9/20: 100%|██████████| 63/63 [00:10<00:00,  6.11it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 10/20: 100%|██████████| 63/63 [00:10<00:00,  5.96it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 11/20: 100%|██████████| 63/63 [00:10<00:00,  6.01it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 12/20: 100%|██████████| 63/63 [00:10<00:00,  5.94it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 13/20: 100%|██████████| 63/63 [00:10<00:00,  6.00it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 14/20: 100%|██████████| 63/63 [00:10<00:00,  5.98it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 15/20: 100%|██████████| 63/63 [00:10<00:00,  6.01it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 16/20: 100%|██████████| 63/63 [00:10<00:00,  5.90it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 17/20: 100%|██████████| 63/63 [00:10<00:00,  6.01it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 18/20: 100%|██████████| 63/63 [00:10<00:00,  5.88it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 19/20: 100%|██████████| 63/63 [00:10<00:00,  5.92it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 20/20: 100%|██████████| 63/63 [00:10<00:00,  5.92it/s, loss=0.0000, acc=1.0000]\n",
        "Training time: 205.56s\n",
        "\n",
        "Evaluating...\n",
        "Test time: 1.06s\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      benign       0.99      0.99      0.99       489\n",
        "   malicious       0.98      0.99      0.98       321\n",
        "\n",
        "    accuracy                           0.99       810\n",
        "   macro avg       0.99      0.99      0.99       810\n",
        "weighted avg       0.99      0.99      0.99       810\n",
        "\n",
        "Confusion Matrix:\n",
        "                 Pred: benign  Pred: malicious\n",
        "True: benign              482                7\n",
        "True: malicious             3              318\n",
        "\n",
        "Detection Rate: 0.9907\n",
        "False Positive Rate: 0.0143\n",
        "F1-score (weighted): 0.9877\n",
        "\n",
        "============================================================\n",
        "EXPERIMENT: Window Size = 500\n",
        "============================================================\n",
        "Train samples: 1986, Test samples: 810\n",
        "\n",
        "--- Input Shapes ---\n",
        "  Syscall input shape:   (batch_size, 500)\n",
        "  Retval input shape:    (batch_size, 500)\n",
        "  Param emb input shape: (batch_size, 500, 384)\n",
        "  After embedding concat: (batch_size, 500, 448)\n",
        "\n",
        "--- Model Architecture & Parameters ---\n",
        "  syscall_embedding.weight: [81, 32] = 2,592 params\n",
        "  retval_embedding.weight: [42586, 32] = 1,362,752 params\n",
        "  convs.0.weight: [64, 448, 3] = 86,016 params\n",
        "  convs.0.bias: [64] = 64 params\n",
        "  convs.1.weight: [64, 448, 5] = 143,360 params\n",
        "  convs.1.bias: [64] = 64 params\n",
        "  convs.2.weight: [64, 448, 7] = 200,704 params\n",
        "  convs.2.bias: [64] = 64 params\n",
        "  fc.0.weight: [64, 192] = 12,288 params\n",
        "  fc.0.bias: [64] = 64 params\n",
        "  fc.3.weight: [2, 64] = 128 params\n",
        "  fc.3.bias: [2] = 2 params\n",
        "  ──────────────────────────────────────────────────\n",
        "  Total parameters:     1,808,098\n",
        "  Trainable parameters: 1,808,098\n",
        "\n",
        "Training...\n",
        "Epoch 1/20: 100%|██████████| 63/63 [00:16<00:00,  3.89it/s, loss=0.0040, acc=0.9466]\n",
        "Epoch 2/20: 100%|██████████| 63/63 [00:18<00:00,  3.44it/s, loss=0.0003, acc=0.9980]\n",
        "Epoch 3/20: 100%|██████████| 63/63 [00:19<00:00,  3.29it/s, loss=0.0001, acc=0.9995]\n",
        "Epoch 4/20: 100%|██████████| 63/63 [00:19<00:00,  3.17it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 5/20: 100%|██████████| 63/63 [00:20<00:00,  3.10it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 6/20: 100%|██████████| 63/63 [00:20<00:00,  3.11it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 7/20: 100%|██████████| 63/63 [00:20<00:00,  3.13it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 8/20: 100%|██████████| 63/63 [00:20<00:00,  3.13it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 9/20: 100%|██████████| 63/63 [00:20<00:00,  3.10it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 10/20: 100%|██████████| 63/63 [00:20<00:00,  3.13it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 11/20: 100%|██████████| 63/63 [00:20<00:00,  3.10it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 12/20: 100%|██████████| 63/63 [00:20<00:00,  3.14it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 13/20: 100%|██████████| 63/63 [00:19<00:00,  3.15it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 14/20: 100%|██████████| 63/63 [00:20<00:00,  3.08it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 15/20: 100%|██████████| 63/63 [00:20<00:00,  3.09it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 16/20: 100%|██████████| 63/63 [00:20<00:00,  3.11it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 17/20: 100%|██████████| 63/63 [00:20<00:00,  3.09it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 18/20: 100%|██████████| 63/63 [00:20<00:00,  3.08it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 19/20: 100%|██████████| 63/63 [00:20<00:00,  3.07it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 20/20: 100%|██████████| 63/63 [00:20<00:00,  3.14it/s, loss=0.0000, acc=1.0000]\n",
        "Training time: 397.73s\n",
        "\n",
        "Evaluating...\n",
        "Test time: 2.01s\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      benign       1.00      0.84      0.91       489\n",
        "   malicious       0.80      1.00      0.89       321\n",
        "\n",
        "    accuracy                           0.90       810\n",
        "   macro avg       0.90      0.92      0.90       810\n",
        "weighted avg       0.92      0.90      0.90       810\n",
        "\n",
        "Confusion Matrix:\n",
        "                 Pred: benign  Pred: malicious\n",
        "True: benign              411               78\n",
        "True: malicious             1              320\n",
        "\n",
        "Detection Rate: 0.9969\n",
        "False Positive Rate: 0.1595\n",
        "F1-score (weighted): 0.9035\n",
        "\n",
        "============================================================\n",
        "EXPERIMENT: Window Size = 1000\n",
        "============================================================\n",
        "Train samples: 1986, Test samples: 810\n",
        "\n",
        "--- Input Shapes ---\n",
        "  Syscall input shape:   (batch_size, 1000)\n",
        "  Retval input shape:    (batch_size, 1000)\n",
        "  Param emb input shape: (batch_size, 1000, 384)\n",
        "  After embedding concat: (batch_size, 1000, 448)\n",
        "\n",
        "--- Model Architecture & Parameters ---\n",
        "  syscall_embedding.weight: [81, 32] = 2,592 params\n",
        "  retval_embedding.weight: [42586, 32] = 1,362,752 params\n",
        "  convs.0.weight: [64, 448, 3] = 86,016 params\n",
        "  convs.0.bias: [64] = 64 params\n",
        "  convs.1.weight: [64, 448, 5] = 143,360 params\n",
        "  convs.1.bias: [64] = 64 params\n",
        "  convs.2.weight: [64, 448, 7] = 200,704 params\n",
        "  convs.2.bias: [64] = 64 params\n",
        "  fc.0.weight: [64, 192] = 12,288 params\n",
        "  fc.0.bias: [64] = 64 params\n",
        "  fc.3.weight: [2, 64] = 128 params\n",
        "  fc.3.bias: [2] = 2 params\n",
        "  ──────────────────────────────────────────────────\n",
        "  Total parameters:     1,808,098\n",
        "  Trainable parameters: 1,808,098\n",
        "\n",
        "Training...\n",
        "Epoch 1/20: 100%|██████████| 63/63 [00:28<00:00,  2.23it/s, loss=0.0054, acc=0.9290]\n",
        "Epoch 2/20: 100%|██████████| 63/63 [00:34<00:00,  1.83it/s, loss=0.0003, acc=0.9985]\n",
        "Epoch 3/20: 100%|██████████| 63/63 [00:36<00:00,  1.73it/s, loss=0.0001, acc=1.0000]\n",
        "Epoch 4/20: 100%|██████████| 63/63 [00:37<00:00,  1.67it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 5/20: 100%|██████████| 63/63 [00:38<00:00,  1.65it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 6/20: 100%|██████████| 63/63 [00:38<00:00,  1.65it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 7/20: 100%|██████████| 63/63 [00:38<00:00,  1.63it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 8/20: 100%|██████████| 63/63 [00:39<00:00,  1.61it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 9/20: 100%|██████████| 63/63 [00:38<00:00,  1.62it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 10/20: 100%|██████████| 63/63 [00:38<00:00,  1.62it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 11/20: 100%|██████████| 63/63 [00:38<00:00,  1.63it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 12/20: 100%|██████████| 63/63 [00:38<00:00,  1.64it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 13/20: 100%|██████████| 63/63 [00:38<00:00,  1.62it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 14/20: 100%|██████████| 63/63 [00:38<00:00,  1.64it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 15/20: 100%|██████████| 63/63 [00:39<00:00,  1.61it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 16/20: 100%|██████████| 63/63 [00:39<00:00,  1.59it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 17/20: 100%|██████████| 63/63 [00:39<00:00,  1.60it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 18/20: 100%|██████████| 63/63 [00:39<00:00,  1.60it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 19/20: 100%|██████████| 63/63 [00:38<00:00,  1.62it/s, loss=0.0000, acc=1.0000]\n",
        "Epoch 20/20: 100%|██████████| 63/63 [00:39<00:00,  1.61it/s, loss=0.0000, acc=1.0000]\n",
        "Training time: 758.89s\n",
        "\n",
        "Evaluating...\n",
        "Test time: 3.96s\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      benign       1.00      0.94      0.97       489\n",
        "   malicious       0.92      1.00      0.96       321\n",
        "\n",
        "    accuracy                           0.96       810\n",
        "   macro avg       0.96      0.97      0.96       810\n",
        "weighted avg       0.97      0.96      0.96       810\n",
        "\n",
        "Confusion Matrix:\n",
        "                 Pred: benign  Pred: malicious\n",
        "True: benign              460               29\n",
        "True: malicious             0              321\n",
        "\n",
        "Detection Rate: 1.0000\n",
        "False Positive Rate: 0.0593\n",
        "F1-score (weighted): 0.9644\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "experiments",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENT: Window Size = 2000\n",
            "============================================================\n",
            "Train samples: 1986, Test samples: 810\n",
            "\n",
            "--- Input Shapes ---\n",
            "  Syscall input shape:   (batch_size, 2000)\n",
            "  Retval input shape:    (batch_size, 2000)\n",
            "  Param emb input shape: (batch_size, 2000, 384)\n",
            "  After embedding concat: (batch_size, 2000, 448)\n",
            "\n",
            "--- Model Architecture & Parameters ---\n",
            "  syscall_embedding.weight: [81, 32] = 2,592 params\n",
            "  retval_embedding.weight: [42586, 32] = 1,362,752 params\n",
            "  convs.0.weight: [64, 448, 3] = 86,016 params\n",
            "  convs.0.bias: [64] = 64 params\n",
            "  convs.1.weight: [64, 448, 5] = 143,360 params\n",
            "  convs.1.bias: [64] = 64 params\n",
            "  convs.2.weight: [64, 448, 7] = 200,704 params\n",
            "  convs.2.bias: [64] = 64 params\n",
            "  fc.0.weight: [64, 192] = 12,288 params\n",
            "  fc.0.bias: [64] = 64 params\n",
            "  fc.3.weight: [2, 64] = 128 params\n",
            "  fc.3.bias: [2] = 2 params\n",
            "  ──────────────────────────────────────────────────\n",
            "  Total parameters:     1,808,098\n",
            "  Trainable parameters: 1,808,098\n",
            "\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 63/63 [00:59<00:00,  1.06it/s, loss=0.0047, acc=0.9391]\n",
            "Epoch 2/20: 100%|██████████| 63/63 [01:10<00:00,  1.12s/it, loss=0.0002, acc=0.9990]\n",
            "Epoch 3/20: 100%|██████████| 63/63 [01:14<00:00,  1.18s/it, loss=0.0000, acc=0.9995]\n",
            "Epoch 4/20: 100%|██████████| 63/63 [01:15<00:00,  1.20s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 5/20: 100%|██████████| 63/63 [01:16<00:00,  1.21s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 6/20: 100%|██████████| 63/63 [01:17<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 7/20: 100%|██████████| 63/63 [01:16<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 8/20: 100%|██████████| 63/63 [01:17<00:00,  1.23s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 9/20: 100%|██████████| 63/63 [01:16<00:00,  1.21s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 10/20: 100%|██████████| 63/63 [01:17<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 11/20: 100%|██████████| 63/63 [01:18<00:00,  1.25s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 12/20: 100%|██████████| 63/63 [01:16<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 13/20: 100%|██████████| 63/63 [01:16<00:00,  1.21s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 14/20: 100%|██████████| 63/63 [01:16<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 15/20: 100%|██████████| 63/63 [01:16<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 16/20: 100%|██████████| 63/63 [01:16<00:00,  1.21s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 17/20: 100%|██████████| 63/63 [01:18<00:00,  1.25s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 18/20: 100%|██████████| 63/63 [01:17<00:00,  1.23s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 19/20: 100%|██████████| 63/63 [01:17<00:00,  1.22s/it, loss=0.0000, acc=1.0000]\n",
            "Epoch 20/20: 100%|██████████| 63/63 [01:17<00:00,  1.23s/it, loss=0.0000, acc=1.0000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1513.77s\n",
            "\n",
            "Evaluating...\n",
            "Test time: 7.93s\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       1.00      0.96      0.98       489\n",
            "   malicious       0.94      1.00      0.97       321\n",
            "\n",
            "    accuracy                           0.98       810\n",
            "   macro avg       0.97      0.98      0.98       810\n",
            "weighted avg       0.98      0.98      0.98       810\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Pred: benign  Pred: malicious\n",
            "True: benign              470               19\n",
            "True: malicious             0              321\n",
            "\n",
            "Detection Rate: 1.0000\n",
            "False Positive Rate: 0.0389\n",
            "F1-score (weighted): 0.9766\n"
          ]
        }
      ],
      "source": [
        "# Run experiments with different window sizes\n",
        "results = []\n",
        "\n",
        "for window_size in WINDOW_SIZES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXPERIMENT: Window Size = {window_size}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = AllFeaturesDataset(\n",
        "        train_files, syscall_encoder, retval_encoder,\n",
        "        param_to_embedding, window_size, PARAM_EMBED_DIM, PAD_PARAM_EMBEDDING\n",
        "    )\n",
        "    test_dataset = AllFeaturesDataset(\n",
        "        test_files, syscall_encoder, retval_encoder,\n",
        "        param_to_embedding, window_size, PARAM_EMBED_DIM, PAD_PARAM_EMBEDDING\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "    \n",
        "    # Print input shapes\n",
        "    print(f\"\\n--- Input Shapes ---\")\n",
        "    print(f\"  Syscall input shape:   (batch_size, {window_size})\")\n",
        "    print(f\"  Retval input shape:    (batch_size, {window_size})\")\n",
        "    print(f\"  Param emb input shape: (batch_size, {window_size}, {PARAM_EMBED_DIM})\")\n",
        "    print(f\"  After embedding concat: (batch_size, {window_size}, {SYSCALL_EMBED_DIM + RETVAL_EMBED_DIM + PARAM_EMBED_DIM})\")\n",
        "    \n",
        "    # Create model\n",
        "    model = CNN1DAllFeatures(\n",
        "        syscall_vocab_size=syscall_vocab_size,\n",
        "        retval_vocab_size=retval_vocab_size,\n",
        "        syscall_embed_dim=SYSCALL_EMBED_DIM,\n",
        "        retval_embed_dim=RETVAL_EMBED_DIM,\n",
        "        param_embed_dim=PARAM_EMBED_DIM,\n",
        "        num_filters=64\n",
        "    ).to(DEVICE)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    # Print model parameter sizes per layer\n",
        "    print(f\"\\n--- Model Architecture & Parameters ---\")\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        param_count = param.numel()\n",
        "        total_params += param_count\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param_count\n",
        "        print(f\"  {name}: {list(param.shape)} = {param_count:,} params\")\n",
        "    print(f\"  {'─'*50}\")\n",
        "    print(f\"  Total parameters:     {total_params:,}\")\n",
        "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "    \n",
        "    # Training\n",
        "    print(f\"\\nTraining...\")\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True)\n",
        "        for syscalls, retvals, param_embs, labels in pbar:\n",
        "            syscalls = syscalls.to(DEVICE)\n",
        "            retvals = retvals.to(DEVICE)\n",
        "            param_embs = param_embs.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(syscalls, retvals, param_embs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            pbar.set_postfix({'loss': f'{total_loss/total:.4f}', 'acc': f'{correct/total:.4f}'})\n",
        "        \n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "    \n",
        "    train_time = time.time() - train_start_time\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    \n",
        "    # Testing\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    test_start_time = time.time()\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for syscalls, retvals, param_embs, labels in test_loader:\n",
        "            syscalls = syscalls.to(DEVICE)\n",
        "            retvals = retvals.to(DEVICE)\n",
        "            param_embs = param_embs.to(DEVICE)\n",
        "            \n",
        "            outputs = model(syscalls, retvals, param_embs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    \n",
        "    test_time = time.time() - test_start_time\n",
        "    print(f\"Test time: {test_time:.2f}s\")\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        'Window Size': window_size,\n",
        "        'Detection Rate': detection_rate,\n",
        "        'False Positive Rate': false_positive_rate,\n",
        "        'F1-score (weighted)': f1_weighted,\n",
        "        'Train Time (s)': train_time,\n",
        "        'Test Time (s)': test_time\n",
        "    })\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['benign', 'malicious']))\n",
        "    \n",
        "    labels_names = ['benign', 'malicious']\n",
        "    cm_df = pd.DataFrame(cm, index=[f'True: {l}' for l in labels_names], columns=[f'Pred: {l}' for l in labels_names])\n",
        "    print(f\"Confusion Matrix:\")\n",
        "    print(cm_df)\n",
        "    \n",
        "    print(f\"\\nDetection Rate: {detection_rate:.4f}\")\n",
        "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
        "    \n",
        "    # Clear GPU memory between experiments\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "summary",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY OF RESULTS (All Features Combined)\n",
            "================================================================================\n",
            " Window Size Detection Rate False Positive Rate F1-score (weighted) Train Time (s) Test Time (s)\n",
            "         250         0.9907              0.0143              0.9877         205.56          1.06\n",
            "         500         0.9969              0.1595              0.9035         397.73          2.01\n",
            "        1000         1.0000              0.0593              0.9644         758.89          3.96\n",
            "        2000         1.0000              0.0389              0.9766        1513.77          7.93\n",
            "\n",
            "Features combined:\n",
            "  - Syscall embedding: 32 dims\n",
            "  - Return value embedding: 32 dims\n",
            "  - Parameter embedding (sentence transformer): 384 dims\n",
            "  - Total: 448 dims per timestep\n"
          ]
        }
      ],
      "source": [
        "# Summary Results Table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF RESULTS (All Features Combined)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Detection Rate'] = results_df['Detection Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['False Positive Rate'] = results_df['False Positive Rate'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['F1-score (weighted)'] = results_df['F1-score (weighted)'].apply(lambda x: f\"{x:.4f}\")\n",
        "results_df['Train Time (s)'] = results_df['Train Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "results_df['Test Time (s)'] = results_df['Test Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\nFeatures combined:\")\n",
        "print(f\"  - Syscall embedding: {SYSCALL_EMBED_DIM} dims\")\n",
        "print(f\"  - Return value embedding: {RETVAL_EMBED_DIM} dims\")\n",
        "print(f\"  - Parameter embedding (sentence transformer): {PARAM_EMBED_DIM} dims\")\n",
        "print(f\"  - Total: {SYSCALL_EMBED_DIM + RETVAL_EMBED_DIM + PARAM_EMBED_DIM} dims per timestep\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pt-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
